<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>ERP measures</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Naumann et al.</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="glyphicon glyphicon-info-sign"></span>
     
    Introduction
  </a>
</li>
<li>
  <a href="R_Script_1_Method_Section.html">
    <span class="glyphicon glyphicon-wrench"></span>
     
    Method section
  </a>
</li>
<li>
  <a href="R_Script_2_EEG_task_measures.html">
    <span class="glyphicon glyphicon-hand-up"></span>
     
    EEG task measures
  </a>
</li>
<li>
  <a href="R_Script_3_ERP_measures.html">
    <span class="glyphicon glyphicon-user"></span>
     
    ERP measures
  </a>
</li>
<li>
  <a href="R_Script_4_Emotion_empathy_measures.html">
    <span class="glyphicon glyphicon-link"></span>
     
    Emotion &amp; Empathy measures
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">ERP measures</h1>

</div>


<!-- Set up workspace -->
<!-- Load and prepare data sets -->
<pre class="r"><code>  # Prepare EEG data --------------------------------------------------------
    # Concatenate ERP table ----------------------------------------------------
      
    # Get RT/Accuracy datafor EEG task
      EEG_behav = readRDS(&quot;./data/EEG_behav_data.rds&quot;, refhook = NULL)
      
    # Get stimulus information 
      Stim_data = readWorksheetFromFile(&quot;./data/Stim_Descr.xlsx&quot;, 
                                        sheet = 1, 
                                        startCol = 1,
                                        endCol = 0)

    # List files of EEG/RT within a folder and get number of participants
      files_eeg = list.files(path=&quot;./data/ERPs&quot;, pattern = &quot;*ind.csv&quot;)
      nfiles = length(files_eeg)
  
    # Combine single ERP trials of participants into data frame   
  
      for (i in 1:nfiles) {
    
      # Get EEG file per subject
        Subj_Data = read.csv(file=paste(&quot;./data/ERPs/&quot;,files_eeg[i], sep = &quot;&quot;), header=TRUE, sep=&quot;,&quot;)
    
      # EEG table transformations -----------------------------------------------
    
        # Add ID
          Subj_Data$ID = substr(files_eeg [i],1,2)
    
        # Re-format single conditions into numbers
          Subj_Data$Condition =as.numeric(as.factor(Subj_Data$Condition))
      
        # Reminder: (p=prime, c=comgruent, ic=incongruent)
          # 1 - p_happy; 2 - p_neutral; 3 - p_angry
          # 4 - c_happy; 5 - c_neutral; 6 - c_angry
          # 7 - ic_happy; 8 - ic_neutral; 9 - ic_angry 
      
        # Add group conditions (prime, congruent, incongruent)
    
        # Create grouping variable 
          grouping = data.frame(single=c(1:9),group_pcic=c(rep(1,3),rep(2,3),rep(3,3)),group_pt=c(rep(1,3),rep(2,6)))
    
        # group_pcic = prime vs congruent vs incongruent, group_pt = prime vs target
    
        # Match grouping variable with subject data
          Subj_Data$Group_pcic = grouping$group_pcic[match(Subj_Data$Condition,grouping$single,nomatch = NA)]
          Subj_Data$Group_pt = grouping$group_pt[match(Subj_Data$Condition,grouping$single,nomatch = NA)]
          
        # Average ROIs
          Subj_Data$mean_ROI_P1 = rowMeans(subset(Subj_Data,select = c(P1_PO3,P1_PO4,P1_O1,P1_O2,P1_Oz)),na.rm = TRUE)
          Subj_Data$mean_ROI_N170l = rowMeans(subset(Subj_Data,select = c(N170l_TP7,N170l_CP5,N170l_P7)),na.rm = TRUE)
          Subj_Data$mean_ROI_N170r = rowMeans(subset(Subj_Data,select = c(N170r_TP8,N170r_CP6,N170r_P8)),na.rm = TRUE)
          Subj_Data$mean_ROI_P3 = rowMeans(subset(Subj_Data,select = c(P3_PO3,P3_PO4,P3_O1,P3_O2,P3_Oz)),na.rm = TRUE)
          
      # Match EEG table with behavioral information  ------------------------------------------------
    
        # Function to map values together (RT values and ERP trial values): match ()
    
        # Match RTs
          Subj_Data$RTs = EEG_behav$RTs[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
    
        # Match Responses 
          Subj_Data$Response = EEG_behav$Response[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
    
        # Match Blocks
          Subj_Data$Block = EEG_behav$Block[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
    
        # Match RT inclusion / exclusion criteria 
          Subj_Data$Exclude_smaller_250ms = EEG_behav$Exclude_smaller_250ms[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
          Subj_Data$Exclude_larger_7s = EEG_behav$Exclude_larger_7s[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
          Subj_Data$Exclude_MAD = EEG_behav$Exclude_MAD[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
    
        # Match randomization / stimulus type
          Subj_Data$EEG_Random = EEG_behav$EEG_Random[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
          Subj_Data$Stim_Type = EEG_behav$Stim_Type[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
        
        # Match chronological age / working memory
          Subj_Data$Age = EEG_behav$Age[match(Subj_Data$ID,EEG_behav$ID,nomatch = NA)]
          Subj_Data$WM = EEG_behav$WM[match(Subj_Data$ID,EEG_behav$ID,nomatch = NA)]
    
    
      # Combine all subject data ------------------------------------------
    
        if (i==1) {
          All_Subj = Subj_Data # first round: create all_subj data frame
        } else {
          All_Subj = rbind(All_Subj,Subj_Data) # add to all_subj data frame 
        }
        
        # Clear previous
          remove(Subj_Data)
    
    }
  
  # Remove EEG_Nr &amp; RT_Nr
    All_Subj = subset(All_Subj, select = -c(EEG_Nr,RT_Nr))
  
  # ID to the front
    All_Subj = All_Subj[, c(18,1:17,19:34)]  
  
  # Define ID as factor
    All_Subj$ID = factor(All_Subj$ID)

  # Remove NAs for amplitudes with no clear indication to a block
    All_Subj=All_Subj[complete.cases(All_Subj[ , 28]),]
 
  # Re-check NAs
    sapply(All_Subj,function(x) sum(is.na(x)))
    
  # De-select outlier participant
    All_Subj = All_Subj[with(All_Subj, !(All_Subj$ID==&quot;05&quot;)), ]</code></pre>
<div id="erp-analysis" class="section level3">
<h3>3.2 ERP analysis</h3>
<p><br></p>
<div id="valence-effects" class="section level4">
<h4>3.2.1 Valence effects</h4>
<hr />
<div id="assumption-checks" class="section level5 tabset tabset-pills">
<h5>Assumption checks</h5>
<div id="lmm_p1-normality-of-residuals" class="section level6">
<h6>LMM_P1: Normality of residuals</h6>
<pre class="r"><code> # Build model &amp; check assumptions -----------------------------------------
        
        # Select &quot;face 1&quot;
          P1_Val = subset(All_Subj,Group_pt == 1) 

        # Prepare fixed factors 
          P1_Val$ID = as.factor(P1_Val$ID)
          P1_Val$Stim_Type = as.factor(P1_Val$Stim_Type)

        # Re-code emotion condition
          P1_Val$Condition[P1_Val$Condition==1] = &quot;happy&quot;
          P1_Val$Condition[P1_Val$Condition==2] = &quot;neutral&quot;
          P1_Val$Condition[P1_Val$Condition==3] = &quot;angry&quot;
        
        # Create factor &amp; set neutral as baseline
          P1_Val$Condition = factor(P1_Val$Condition, levels=c(&quot;neutral&quot;,&quot;happy&quot;,&quot;angry&quot;))
        
        # Set treatment contrast
          contrasts(P1_Val$Condition) = contr.treatment(3)
  
      # 1) Check properties of DV / residuals 

        # Check which transformation of DV is suitable
          # we have positive and negative single trial values
          # hence: add constant value prior to box-cox
          
          P1_Val$Trans_P1 = P1_Val$mean_ROI_P1 + 1 - min(P1_Val$mean_ROI_P1)
      
        # To make sure residuals follow ND: Calculate box-cox plot
           boxcox(P1_Val$Trans_P1 ~ P1_Val$Condition)   </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P1_val_res-1.png" width="768" /></p>
<pre class="r"><code>        # Visualize normality assumption of residuals (without log transform)
          mod_P1_val = lm(Trans_P1 ~ Condition, data=P1_Val)
          res.mod_P1_val = residuals(mod_P1_val)
          
          par(mfrow=c(1,2))
          qqpl_mod_P1_val = qqPlot(res.mod_P1_val, main=&quot;QQplot before transformation&quot;)    
          norm_mod_P1_val = plot(density(res.mod_P1_val), main=&quot;Density plot before transformation&quot;)  </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P1_val_res-2.png" width="768" /></p>
<pre class="r"><code>          par(mfrow=c(1,1))</code></pre>
<hr />
</div>
<div id="lmm_p1-random-effect-structure" class="section level6">
<h6>LMM_P1: Random effect structure</h6>
<pre class="r"><code>      # 3) Construct full model      
            
        # Add contrast columns
          mm_c =  model.matrix( ~ Condition, P1_Val) 
        
        # Attach to dataframe
          P1_Val[,(ncol(P1_Val)+1):(ncol(P1_Val)+3)] = mm_c
          names(P1_Val)[(ncol(P1_Val)-2):ncol(P1_Val)] = c(&quot;Mean&quot;,&quot;Hap_Neu&quot;, &quot;Ang_Neu&quot;) 
        
        # Build model 
          mod_P1_val.lmer1 = lmer(mean_ROI_P1 ~ 
                              Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                              (1 + Hap_Neu + Ang_Neu||ID) +
                              (1 + Hap_Neu + Ang_Neu||Stim_Type),
                              data = P1_Val,
                              control=lmerControl(calc.derivs = FALSE))
        
        # 1st: check how many zero variance terms you got in random effects
          summary(rePCA(mod_P1_val.lmer1))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                          [,1]   [,2] [,3]
## Standard deviation     0.0812 0.0217    0
## Proportion of Variance 0.9335 0.0665    0
## Cumulative Proportion  0.9335 1.0000    1
## 
## $ID
## Importance of components:
##                         [,1]   [,2]    [,3]
## Standard deviation     0.355 0.0924 0.03350
## Proportion of Variance 0.929 0.0631 0.00829
## Cumulative Proportion  0.929 0.9917 1.00000</code></pre>
<pre class="r"><code>        # 2nd: check which random terms explain the least variance
          print(VarCorr(mod_P1_val.lmer1),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups      Name        Variance
##  Stim_Type   Ang_Neu       0.0931
##  Stim_Type.1 Hap_Neu       1.3073
##  Stim_Type.2 (Intercept)   0.0000
##  ID          Ang_Neu       1.6913
##  ID.1        Hap_Neu       0.2223
##  ID.2        (Intercept)  24.9065
##  Residual                198.0550</code></pre>
<pre class="r"><code>        # Remove intercepts/slopes based on variance check 
          mod_P1_val.lmer2 = lmer(mean_ROI_P1 ~ 
                              Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                              (1 + Hap_Neu + Ang_Neu||ID) +
                              (0 + Hap_Neu||Stim_Type),
                              data = P1_Val,
                              control=lmerControl(calc.derivs = FALSE))
        
        # Re-check the model
          summary(rePCA(mod_P1_val.lmer2))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                         [,1]
## Standard deviation     0.081
## Proportion of Variance 1.000
## Cumulative Proportion  1.000
## 
## $ID
## Importance of components:
##                         [,1]   [,2]     [,3]
## Standard deviation     0.355 0.0938 0.000558
## Proportion of Variance 0.935 0.0652 0.000000
## Cumulative Proportion  0.935 1.0000 1.000000</code></pre>
<pre class="r"><code>          print(VarCorr(mod_P1_val.lmer2),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups    Name        Variance   
##  Stim_Type Hap_Neu       1.2991677
##  ID        Ang_Neu       1.7416634
##  ID.1      Hap_Neu       0.0000617
##  ID.2      (Intercept)  24.9577644
##  Residual              198.1225649</code></pre>
<pre class="r"><code>        # Likelihood ratio testing
        
          # For ID
            mod_P1_val.lmer3 = lmer(mean_ROI_P1 ~ 
                                  Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                                  (1 |ID) +
                                  (0 + Hap_Neu + Ang_Neu||Stim_Type),
                                data = P1_Val,
                                control=lmerControl(calc.derivs = FALSE))
          
          # Calculate ANOVA
            anova(mod_P1_val.lmer2,mod_P1_val.lmer3)</code></pre>
<pre><code>## Data: P1_Val
## Models:
## mod_P1_val.lmer3: mean_ROI_P1 ~ Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + (1 | 
## mod_P1_val.lmer3:     ID) + (0 + Hap_Neu + Ang_Neu || Stim_Type)
## mod_P1_val.lmer2: mean_ROI_P1 ~ Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + (1 + 
## mod_P1_val.lmer2:     Hap_Neu + Ang_Neu || ID) + (0 + Hap_Neu || Stim_Type)
##                  Df   AIC   BIC logLik deviance Chisq Chi Df
## mod_P1_val.lmer3  9 23332 23385 -11657    23314             
## mod_P1_val.lmer2 10 23333 23393 -11657    23313  0.33      1
##                  Pr(&gt;Chisq)
## mod_P1_val.lmer3           
## mod_P1_val.lmer2       0.56</code></pre>
<pre class="r"><code>          # Stimulus type
            mod_P1_val.lmer4 = lmer(mean_ROI_P1 ~ 
                              Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                              (1 + Ang_Neu||ID) +
                              (1 |Stim_Type),
                            data = P1_Val,
                            control=lmerControl(calc.derivs = FALSE))
            
          # Calculate ANOVA
            anova(mod_P1_val.lmer2,mod_P1_val.lmer4)</code></pre>
<pre><code>## Data: P1_Val
## Models:
## mod_P1_val.lmer4: mean_ROI_P1 ~ Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + (1 + 
## mod_P1_val.lmer4:     Ang_Neu || ID) + (1 | Stim_Type)
## mod_P1_val.lmer2: mean_ROI_P1 ~ Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + (1 + 
## mod_P1_val.lmer2:     Hap_Neu + Ang_Neu || ID) + (0 + Hap_Neu || Stim_Type)
##                  Df   AIC   BIC logLik deviance Chisq Chi Df
## mod_P1_val.lmer4  9 23331 23385 -11657    23313             
## mod_P1_val.lmer2 10 23333 23393 -11657    23313  0.29      1
##                  Pr(&gt;Chisq)
## mod_P1_val.lmer4           
## mod_P1_val.lmer2       0.59</code></pre>
<pre class="r"><code>          # Final model
            mod_P1_val.lmer4 = lmer(mean_ROI_P1 ~ 
                              Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                              (1 |ID) +
                              (1 |Stim_Type),
                            data = P1_Val,
                            control=lmerControl(calc.derivs = FALSE))</code></pre>
<hr />
</div>
<div id="lmm_p1-homoscedasticity" class="section level6">
<h6>LMM_P1: Homoscedasticity</h6>
<pre class="r"><code>      # 4) Check homoscedasticity  
        
          # Whether residuals are equally distributed along regression line 
            plot(fitted(mod_P1_val.lmer4), residuals(mod_P1_val.lmer4))
            abline(0, 0)    </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P1_val_homosk-1.png" width="768" /></p>
<hr />
</div>
<div id="lmm_n170-normality-of-residuals" class="section level6">
<h6>LMM_N170: Normality of residuals</h6>
<pre class="r"><code># Transform dataset so that left/right hemisphere are accounted for 
          N170_Val = gather (All_Subj, Elect_site, N170_Amplitude, mean_ROI_N170l:mean_ROI_N170r, factor_key = TRUE)
        
        # Add variable name
          N170_Val$Elect_site = as.character(N170_Val$Elect_site)
          N170_Val$Elect_site[N170_Val$Elect_site == &quot;mean_ROI_N170l&quot;] = &#39;left&#39;
          N170_Val$Elect_site[N170_Val$Elect_site == &quot;mean_ROI_N170r&quot;] = &quot;right&quot;
 
        # Prepare fixed factors 
          N170_Val$ID = as.factor(N170_Val$ID)
          N170_Val$Stim_Type = as.factor(N170_Val$Stim_Type)
          N170_Val$Elect_site = factor(N170_Val$Elect_site)
        
        # Select primes
          N170_Val = subset(N170_Val,Group_pt == 1) 
        
        # Re-code values for emotion variable
          N170_Val$Condition[N170_Val$Condition==1] = &quot;happy&quot;
          N170_Val$Condition[N170_Val$Condition==2] = &quot;neutral&quot;
          N170_Val$Condition[N170_Val$Condition==3] = &quot;angry&quot;
        
        # Create factor, get neutral as baseline
          N170_Val$Condition = factor(N170_Val$Condition, levels=c(&quot;neutral&quot;,&quot;happy&quot;,&quot;angry&quot;))
        
        # Set treatment contrast
          (contrasts(N170_Val$Condition) = contr.treatment(3))
          
        # Set contrast for hemisphere
          (contrasts(N170_Val$Elect_site) = contr.sum(2)/2)
        
        
      # 1) Check properties of DV / residuals 
        
        # Check which transformation of DV is suitable
          # we have positive and negative single trial values
          # hence: add constant value prior to box-cox
          
          N170_Val$Trans_N170 = N170_Val$N170_Amplitude + 1 - min(N170_Val$N170_Amplitude)

        # To make sure residuals follow ND: Calculate box-cox plot
           boxcox(N170_Val$Trans_N170 ~ N170_Val$Condition)   </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/N170_val_res-1.png" width="768" /></p>
<pre class="r"><code>        # Visualize normality assumption of residuals (without log transform)
          mod_N170_val = lm(Trans_N170 ~ Condition, data=N170_Val)
          res.mod_N170_val = residuals(mod_N170_val)
          
          par(mfrow=c(1,2))
          qqpl_mod_N170_val = qqPlot(res.mod_N170_val, main=&quot;QQplot before transformation&quot;)    
          norm_mod_N170_val = plot(density(res.mod_N170_val), main=&quot;Density plot before transformation&quot;)  </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/N170_val_res-2.png" width="768" /></p>
<pre class="r"><code>          par(mfrow=c(1,1))            </code></pre>
<hr />
</div>
<div id="lmm_n170-random-effect-structure" class="section level6">
<h6>LMM_N170: Random effect structure</h6>
<pre class="r"><code> # 3) Construct full model    
                  
        # Add contrast columns
          mm_c =  model.matrix( ~ Condition + Elect_site + Condition*Elect_site, N170_Val) 
        
        # Attach to dataframe
          N170_Val[,(ncol(N170_Val)+1):(ncol(N170_Val)+6)] = mm_c
          names(N170_Val)[(ncol(N170_Val)-5):ncol(N170_Val)] = c(&quot;Mean&quot;, &quot;Hap_Neu&quot;, &quot;Ang_Neu&quot;, &quot;Elect_site&quot;, &quot;Hap_NeuxElect_site&quot;, &quot;Ang_NeuxElect_site&quot;) 
          
        # Get model
          mod_N170_val.lmer1 = lmer(N170_Amplitude ~ 
                                      Hap_Neu + Ang_Neu+ Hap_NeuxElect_site + Ang_NeuxElect_site + scale(Age) + scale(WM) + 
                                      (1 + Hap_Neu + Ang_Neu + Hap_NeuxElect_site + Ang_NeuxElect_site + Elect_site||ID) +
                                      (1 + Hap_Neu + Ang_Neu + Hap_NeuxElect_site + Ang_NeuxElect_site + Elect_site||Stim_Type),
                                    data = N170_Val,
                                    control=lmerControl(calc.derivs = FALSE))
        
        # 1st: check how many zero variance terms you got in random effects
          summary(rePCA(mod_N170_val.lmer1))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                            [,1]     [,2]      [,3] [,4] [,5]
## Standard deviation     0.000756 0.000358 0.0000584    0    0
## Proportion of Variance 0.812930 0.182230 0.0048500    0    0
## Cumulative Proportion  0.812930 0.995150 1.0000000    1    1
##                        [,6] [,7]
## Standard deviation        0    0
## Proportion of Variance    0    0
## Cumulative Proportion     1    1
## 
## $ID
## Importance of components:
##                         [,1]  [,2]  [,3]   [,4]   [,5]
## Standard deviation     0.247 0.238 0.138 0.0975 0.0709
## Proportion of Variance 0.403 0.374 0.127 0.0630 0.0333
## Cumulative Proportion  0.403 0.777 0.904 0.9666 1.0000
##                            [,6] [,7]
## Standard deviation     0.000535    0
## Proportion of Variance 0.000000    0
## Cumulative Proportion  1.000000    1</code></pre>
<pre class="r"><code>        # 2nd: check which random terms explain the least variance
          print(VarCorr(mod_N170_val.lmer1),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups      Name               Variance       Corr 
##  Stim_Type   Elect_siteleft       0.0000005173      
##              Elect_siteright      0.0000000028 1.00 
##  Stim_Type.1 Ang_NeuxElect_site   0.0000195534      
##  Stim_Type.2 Hap_NeuxElect_site   0.0000872300      
##  Stim_Type.3 Ang_Neu              0.0000000000      
##  Stim_Type.4 Hap_Neu              0.0000000000      
##  Stim_Type.5 (Intercept)          0.0000000000      
##  ID          Elect_siteleft       6.7855707893      
##              Elect_siteright      5.4108726248 -0.51
##  ID.1        Ang_NeuxElect_site   0.7679492567      
##  ID.2        Hap_NeuxElect_site   1.4497871651      
##  ID.3        Ang_Neu              0.0000000000      
##  ID.4        Hap_Neu              0.0000436593      
##  ID.5        (Intercept)          8.6095643363      
##  Residual                       152.5996257761</code></pre>
<pre class="r"><code>        # Improved model
          mod_N170_val.lmer2 = lmer(N170_Amplitude ~ 
                                      Hap_Neu + Ang_Neu + Hap_NeuxElect_site + Ang_NeuxElect_site + scale(Age) + scale(WM) + 
                                      (1 |ID),
                                      data = N170_Val,
                                      control=lmerControl(calc.derivs = FALSE))
        # Re-check the model
          summary(rePCA(mod_N170_val.lmer2))</code></pre>
<pre><code>## $ID
## Importance of components:
##                         [,1]
## Standard deviation     0.254
## Proportion of Variance 1.000
## Cumulative Proportion  1.000</code></pre>
<pre class="r"><code>          print(VarCorr(mod_N170_val.lmer2),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups   Name        Variance
##  ID       (Intercept)  10.1   
##  Residual             156.6</code></pre>
<hr />
</div>
<div id="lmm_n170-homoscedasticity" class="section level6">
<h6>LMM_N170: Homoscedasticity</h6>
<pre class="r"><code>        # 4) Check homoscedasticity  
        
        # Whether residuals are equally distributed along regression line 
          plot(fitted(mod_N170_val.lmer2), residuals(mod_N170_val.lmer2))
          abline(0, 0)    </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/N170_val_homosk-1.png" width="768" /></p>
<hr />
</div>
<div id="lmm_p3-normality-of-residuals" class="section level6">
<h6>LMM_P3: Normality of residuals</h6>
<pre class="r"><code> # Build model &amp; check assumptions ---------------------------------------

        # Select primes
          P3_Val = subset(All_Subj, Group_pt == 1) 

        # Prepare fixed factors 
          P3_Val$ID = as.factor(P3_Val$ID)
          P3_Val$Stim_Type = as.factor(P3_Val$Stim_Type)
        
        # Re-Name values of emotion condition
          P3_Val$Condition[P3_Val$Condition==1] = &quot;happy&quot;
          P3_Val$Condition[P3_Val$Condition==2] = &quot;neutral&quot;
          P3_Val$Condition[P3_Val$Condition==3] = &quot;angry&quot;
        
        # Create factor, get neutral as baseline
          P3_Val$Condition = factor(P3_Val$Condition, levels=c(&quot;neutral&quot;,&quot;happy&quot;,&quot;angry&quot;))
        
        # Set treatment contrast
          (contrasts(P3_Val$Condition) = contr.treatment(3))
        
      # 1) Check properties of DV / residuals 
        
        # Check which transformation of DV is suitable
          # we have positive and negative single trial values
          # hence: add constant value prior to box-cox
          
          P3_Val$Trans_P3 = P3_Val$mean_ROI_P3 + 1 - min(P3_Val$mean_ROI_P3)
      
        # To make sure residuals follow ND: Calculate box-cox plot
           boxcox(P3_Val$Trans_P3 ~ P3_Val$Condition)   </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P3_val_res-1.png" width="768" /></p>
<pre class="r"><code>        # Visualize normality assumption of residuals (without log transform)
          mod_P3_val = lm(Trans_P3 ~ Condition, data=P3_Val)
          res.mod_P3_val = residuals(mod_P3_val)
          
          par(mfrow=c(1,2))
          qqpl_mod_P3_val = qqPlot(res.mod_P3_val, main=&quot;QQplot before transformation&quot;)    
          norm_mod_P3_val = plot(density(res.mod_P3_val), main=&quot;Density plot before transformation&quot;)  </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P3_val_res-2.png" width="768" /></p>
<pre class="r"><code>          par(mfrow=c(1,1))</code></pre>
<hr />
</div>
<div id="lmm_p3-random-effect-structure" class="section level6">
<h6>LMM_P3: Random effect structure</h6>
<pre class="r"><code>      # 3) Construct full model     
            
        # Add contrast columns
          mm_c =  model.matrix( ~ Condition, P3_Val) 
        
        # Attach to dataframe
          P3_Val[,(ncol(P3_Val)+1):(ncol(P3_Val)+3)] = mm_c
        
          names(P3_Val)[(ncol(P3_Val)-2):ncol(P3_Val)] = c(&quot;Mean&quot;,&quot;Hap_Neu&quot;, &quot;Ang_Neu&quot;) 
        
        # Get model 
          mod_P3_val.lmer1 = lmer(mean_ROI_P3 ~ 
                                Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                                (1 + Hap_Neu + Ang_Neu||ID) +
                                (1 + Hap_Neu + Ang_Neu||Stim_Type),
                              data = P3_Val,
                              control=lmerControl(calc.derivs = FALSE))
        
        # 1st: check how many zero variance terms you got in random effects
          summary(rePCA(mod_P3_val.lmer1))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                          [,1]   [,2]      [,3]
## Standard deviation     0.0352 0.0327 0.0000431
## Proportion of Variance 0.5363 0.4637 0.0000000
## Cumulative Proportion  0.5363 1.0000 1.0000000
## 
## $ID
## Importance of components:
##                         [,1]    [,2]      [,3]
## Standard deviation     0.325 0.00558 0.0000293
## Proportion of Variance 1.000 0.00029 0.0000000
## Cumulative Proportion  1.000 1.00000 1.0000000</code></pre>
<pre class="r"><code>        # 2nd: check which random terms explain the least variance
          print(VarCorr(mod_P3_val.lmer1),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups      Name        Variance     
##  Stim_Type   Ang_Neu       0.296923659
##  Stim_Type.1 Hap_Neu       0.000000516
##  Stim_Type.2 (Intercept)   0.343408974
##  ID          Ang_Neu       0.008640992
##  ID.1        Hap_Neu       0.000000238
##  ID.2        (Intercept)  29.397507634
##  Residual                277.592363474</code></pre>
<pre class="r"><code>        # Improved model
          mod_P3_val.lmer2 = lmer(mean_ROI_P3 ~ 
                                    Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                                    (1 | ID) +
                                    (1 + Ang_Neu||Stim_Type),
                                  data = P3_Val,
                                  control=lmerControl(calc.derivs = FALSE))
          
        # Re-check the model
          summary(rePCA(mod_P3_val.lmer2))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                          [,1]   [,2]
## Standard deviation     0.0353 0.0325
## Proportion of Variance 0.5411 0.4589
## Cumulative Proportion  0.5411 1.0000
## 
## $ID
## Importance of components:
##                         [,1]
## Standard deviation     0.325
## Proportion of Variance 1.000
## Cumulative Proportion  1.000</code></pre>
<pre class="r"><code>          print(VarCorr(mod_P3_val.lmer2),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups      Name        Variance
##  Stim_Type   Ang_Neu       0.293 
##  Stim_Type.1 (Intercept)   0.346 
##  ID          (Intercept)  29.371 
##  Residual                277.595</code></pre>
<pre class="r"><code>        # Likelihood ratio testing 
        
          # Stimulus type 
            mod_P3_val.lmer3 = lmer(mean_ROI_P3 ~ 
                                  Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                                  (1 |ID) +
                                  (1 |Stim_Type),
                                data = P3_Val,
                                control=lmerControl(calc.derivs = FALSE))

          # Calculate ANOVA 
            anova(mod_P3_val.lmer2, mod_P3_val.lmer3)</code></pre>
<pre><code>## Data: P3_Val
## Models:
## mod_P3_val.lmer3: mean_ROI_P3 ~ Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + (1 | 
## mod_P3_val.lmer3:     ID) + (1 | Stim_Type)
## mod_P3_val.lmer2: mean_ROI_P3 ~ Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + (1 | 
## mod_P3_val.lmer2:     ID) + (1 + Ang_Neu || Stim_Type)
##                  Df   AIC   BIC logLik deviance Chisq Chi Df
## mod_P3_val.lmer3  8 24282 24330 -12133    24266             
## mod_P3_val.lmer2  9 24284 24338 -12133    24266     0      1
##                  Pr(&gt;Chisq)
## mod_P3_val.lmer3           
## mod_P3_val.lmer2       0.96</code></pre>
<pre class="r"><code>        # Final model
          mod_P3_val.lmer4 = lmer(mean_ROI_P3 ~ 
                              Hap_Neu + Ang_Neu + scale(Age) + scale(WM) + 
                              (1 |ID) +
                              (1 |Stim_Type),
                            data = P3_Val,
                            control=lmerControl(calc.derivs = FALSE))</code></pre>
<hr />
</div>
<div id="lmm_p3-homoscedasticity" class="section level6">
<h6>LMM_P3: Homoscedasticity</h6>
<pre class="r"><code>      # 4) Check homoscedasticity  
        
        # Whether residuals are equally dsitributed along regression line 
          plot(fitted(mod_P3_val.lmer4), residuals(mod_P3_val.lmer4))
          abline(0, 0)       </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P3_val_homosk-1.png" width="768" /></p>
<hr />
</div>
</div>
<div id="p1" class="section level5">
<h5>3.2.1.1 P1</h5>
<p>We tested whether P1 amplitudes were larger for emotional (angry or happy) in comparison to neutral stimuli at “face 1” (See <strong>Figure X A</strong>). The best-fitting model included random intercepts for participants and stimulus. P1 Amplitudes at “face 1” were significantly larger for angry in comparison to neutral facial expressions (<span class="math inline">\(\hat{β}\)</span> = 1.6, <em>p</em> &lt;0.05). No difference was found for the contrast of happy vs neutral faces (<span class="math inline">\(\hat{β}\)</span> = 0.99, <em>p</em> = 0.12). None of the covariates reached significance (age: <span class="math inline">\(\hat{β}\)</span> = 1.16, <em>p</em> = 0.25; working memory: <span class="math inline">\(\hat{β}\)</span> = -0.1, <em>p</em> = 0.92; see <strong>Table X</strong>).</p>
<pre class="r"><code># Load data
        Prime_data = read.csv(&quot;./data/ERPs/ROI_P1_prime.csv&quot;,header = TRUE)

      # De-select participants
        Prime_data = Prime_data[with(Prime_data, !(Prime_data$ID==&quot;05&quot;)), ]

      # Select time window
        Prime_data = Prime_data[(Prime_data$Time &gt;= -200)&amp; (Prime_data$Time &lt;= 600),]

      # Rename conditions
        Prime_data$Condition[Prime_data$Condition == 1]=&#39;happy&#39;;
        Prime_data$Condition[Prime_data$Condition == 2]=&#39;neutral&#39;;
        Prime_data$Condition[Prime_data$Condition == 3]=&#39;angry&#39;;

      # Select conditions of interest
        Prime_data_all_emo_sep = Prime_data[(Prime_data$Condition == &#39;happy&#39;)  | (Prime_data$Condition == &#39;angry&#39;) | (Prime_data$Condition == &#39;neutral&#39;),]

      # Plot data
        P1_val_traj = ggplot(Prime_data_all_emo_sep,aes(Time,ROI_Average))+
          ggtitle(&quot;P1 &amp; P3&quot;) +
          theme(panel.background = element_blank(), panel.border = element_rect(colour = &quot;grey&quot;, fill=NA, size=2),
                axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), legend.text=element_text(size=7),
                legend.key = element_rect(fill = &quot;white&quot;))+
          stat_summary(fun.y = mean, geom = &quot;line&quot;, size = 1, linetype = &quot;solid&quot;, aes(colour= Condition))+
          scale_color_discrete(guide = guide_legend(override.aes = list(color = &quot;white&quot;)))+
          #scale_color_OkabeIto()+
          scale_colour_manual(values = c(&quot;#FF5B4F&quot;,&quot;#000000&quot;,&quot;#276CB3&quot;))+
          #theme(axis.title.x=element_blank())+      # to turn of x-axis title
          #theme(axis.title.y=element_blank())+      # to turn of y-axis title
          #theme(text=element_text(family=&quot;Coves&quot;, face=&quot;bold&quot;, size=18))+
          labs(x = &quot;\ntime (ms)&quot;,y = expression(paste(&quot;Mean amplitude across ROI [&quot;,mu,&quot;V]&quot;)),colour = &quot;&quot;)+
          theme(legend.position=&quot;bottom&quot;) +
          coord_cartesian(ylim=c(-2, 16),xlim=c(-100,600)) +
          scale_y_continuous(breaks=seq(-2,16,2))+
          scale_x_continuous(breaks=seq(-100,600,100))+
          geom_vline(xintercept = 0, linetype = &quot;dashed&quot;,colour=&quot;grey&quot; )+
          geom_hline(yintercept = 0, linetype = &quot;dashed&quot;,colour=&quot;grey&quot;)


  # N170 trajectories

      # Load data
        Prime_data_l = read.csv(&quot;./data/ERPs/left_ROI_N170_prime.csv&quot;,header = TRUE)
        Prime_data_r = read.csv(&quot;./data/ERPs/right_ROI_N170_prime.csv&quot;,header = TRUE)

      # LEFT HEMISPHERE

      # Select time windows
        Prime_data_l = Prime_data_l[(Prime_data_l$Time &gt;= -200)&amp; (Prime_data_l$Time &lt;= 600),]

      # De-select participants
        Prime_data_l = Prime_data_l[with(Prime_data_l, !(Prime_data_l$ID==&quot;05&quot;)), ]

      # Rename conditions
        Prime_data_l$Condition[Prime_data_l$Condition == 1]=&#39;happy&#39;;
        Prime_data_l$Condition[Prime_data_l$Condition == 2]=&#39;neutral&#39;;
        Prime_data_l$Condition[Prime_data_l$Condition == 3]=&#39;angry&#39;;

      # Select conditions of interest
        Prime_data_all_emo_sep_l = Prime_data_l[(Prime_data_l$Condition == &#39;happy&#39;)  | (Prime_data_l$Condition == &#39;angry&#39;) | (Prime_data_l$Condition == &#39;neutral&#39;),]

      # Plot data
        N170l_val_traj = ggplot(Prime_data_all_emo_sep_l,aes(Time,ROI_Average))+
          ggtitle(&quot;Left Hemisphere: N170&quot;)+
          theme(panel.background = element_blank(),panel.border = element_rect(colour = &quot;grey&quot;, fill=NA, size=2),
                axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), legend.text=element_text(size=7),
                legend.key = element_rect(fill = &quot;white&quot;))+
          stat_summary(fun.y = mean,geom = &quot;line&quot;,size = 1, linetype = &quot;solid&quot;, aes(colour= Condition))+
          #scale_color_OkabeIto()+
          scale_colour_manual(values = c(&quot;#FF5B4F&quot;,&quot;#000000&quot;,&quot;#276CB3&quot;))+
          #theme(text=element_text(family=&quot;Coves&quot;, face=&quot;bold&quot;, size=15))+
          #theme(axis.title.x=element_blank())+      # to turn of x-axis title
          #theme(axis.title.y=element_blank())+      # to turn of y-axis title
          #theme(legend.position=&quot;none&quot;)+            # to turn of legend
          theme(legend.position=&quot;bottom&quot;) +
          labs(x = &quot;\ntime (ms)&quot;,y = expression(paste(&quot;Mean amplitude across ROI [&quot;,mu,&quot;V]&quot;)),colour = &quot;&quot;)+
          coord_cartesian(ylim=c(-6,6),xlim=c(-100,600)) +
          scale_y_continuous(breaks=seq(-6,6,2))+
          scale_x_continuous(breaks=seq(-100,600,100))+
          geom_vline(xintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot; )+
          geom_hline(yintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot;)

      # RIGHT HEMISPHERE

      # Select time window
        Prime_data_r = Prime_data_r[(Prime_data_r$Time &gt;= -200)&amp; (Prime_data_r$Time &lt;= 600),]

      # De-select participants
        Prime_data_r = Prime_data_r[with(Prime_data_r, !(Prime_data_r$ID==&quot;05&quot;)), ]

      # Rename conditions
        Prime_data_r$Condition[Prime_data_r$Condition == 1]=&#39;happy&#39;;
        Prime_data_r$Condition[Prime_data_r$Condition == 2]=&#39;neutral&#39;;
        Prime_data_r$Condition[Prime_data_r$Condition == 3]=&#39;angry&#39;;

      # Select conditions of interest
        Prime_data_all_emo_sep_r = Prime_data_r[(Prime_data_r$Condition == &#39;happy&#39;)  | (Prime_data_r$Condition == &#39;angry&#39;) | (Prime_data_r$Condition == &#39;neutral&#39;),]

      # Plot data

       N170r_val_traj = ggplot(Prime_data_all_emo_sep_r,aes(Time,ROI_Average))+
         ggtitle(&quot;Right Hemisphere: N170&quot;)+
          theme(panel.background = element_blank(),panel.border = element_rect(colour = &quot;grey&quot;, fill=NA, size=2),
                axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), legend.text=element_text(size=7),
                legend.key = element_rect(fill = &quot;white&quot;))+
          stat_summary(fun.y = mean, geom = &quot;line&quot;,size = 1, linetype = &quot;solid&quot;, aes(colour= Condition))+
          # scale_color_OkabeIto()+
          scale_colour_manual(values = c(&quot;#FF5B4F&quot;,&quot;#000000&quot;,&quot;#276CB3&quot;))+
          #theme(text=element_text(family=&quot;Coves&quot;, face=&quot;bold&quot;, size=15))+
          #theme(axis.title.x=element_blank())+      # to turn of x-axis title
          #theme(axis.title.y=element_blank())+      # to turn of y-axis title
          #theme(legend.position=&quot;none&quot;)+            # to turn of legend
          theme(legend.position=&quot;bottom&quot;)+
          labs(x = &quot;\ntime (ms)&quot;,y = expression(paste(&quot;Mean amplitude across ROI [&quot;,mu,&quot;V]&quot;)),colour = &quot;&quot;)+
          coord_cartesian(ylim=c(-6,6),xlim=c(-100,600)) +
          scale_y_continuous(breaks=seq(-6,6,2))+
          scale_x_continuous(breaks=seq(-100,600,100))+
          geom_vline(xintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot; )+
          geom_hline(yintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot;)


# Combine plots
      combine_plots(P1_val_traj, N170l_val_traj, N170r_val_traj,
                               ncol = 3, nrow=1,
                               labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;),
                               caption.color = &quot;black&quot;,
                               caption.vjust = 0,
                               caption.hjust = 1.3,
                               caption.text = &quot;Figure XX: ERP trajectories for emotion effects&quot;)</code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/ERPs_val_traj-1.png" width="768" /></p>
</div>
<div id="n170" class="section level5">
<h5>3.2.1.2 N170</h5>
<p>We also checked whether emotional faces elicited larger N170 amplitudes compared to neutral faces at “face 1” (See <strong>Figure X B,C</strong>). As previous research has shown that differences in N170 amplitudes across hemispheres can be found in developmental populations (e.g., Adolphs, 2002), we also included hemisphere as a fixed effect factor (left vs right hemisphere). The best fitting model included participant as random intercept. In contrast to our hypothesis, no differences between happy or angry faces in contrast to neutral faces were detected (happy-neutral: <span class="math inline">\(\hat{β}\)</span> = -0.08, <em>p</em> = 0.84; angry-neutral: <span class="math inline">\(\hat{β}\)</span> = 0.57, <em>p</em> = 0.16). None of the interactions of hemisphere with the emotion contrasts, nor covariates reached significance (see <strong>Table XX</strong>).</p>
<pre class="r"><code>    # Load topography information
      Topo_Emo = read.csv(file=&quot;./data/ERPs/ERPs_Topo_Emotions.csv&quot;, header=TRUE, sep=&quot;,&quot;)

    # Exclude participant
      Topo_Emo = Topo_Emo[with(Topo_Emo, !(Topo_Emo$ID==5)), ]

    # Re-name to fit topoplot function
      names(Topo_Emo)[names(Topo_Emo) == &quot;Time&quot;] = &quot;time&quot;

    # Change from wide to long format for electrodes
      Topo_Emo = gather(Topo_Emo, electrode, amplitude, Fp1:Oz, factor_key=TRUE)

    # Rename A1/A2
      names(Topo_Emo)[names(Topo_Emo) == &quot;A1&quot;] &lt;- &quot;TP9&quot;
      names(Topo_Emo)[names(Topo_Emo) == &quot;A2&quot;] &lt;- &quot;TP10&quot;

    # Plot topoplots for happy
      Topo_Emo_Hap = subset(Topo_Emo, Condition == 1)

    # Plot topoplots for neutral
      Topo_Emo_Neu = subset(Topo_Emo, Condition == 2)

    # Plot topoplots for angry
      Topo_Emo_Ang = subset(Topo_Emo, Condition == 3)

    # P1s
      P1_neu=topoplot(Topo_Emo_Neu, time_lim = c(80, 120),interp_limit = &quot;head&quot;, limits = c(-5,15))+
        ggtitle(&quot;P1 (80-120 ms)&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;neutral&quot;, size=3)

      P1_hap=topoplot(Topo_Emo_Hap, time_lim = c(80, 120),interp_limit = &quot;head&quot;, limits = c(-5,15))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;happy&quot;, size=3)

      P1_ang=topoplot(Topo_Emo_Ang, time_lim = c(80, 120),interp_limit = &quot;head&quot;, limits = c(-5,15))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;angry&quot;, size=3)

    # N170s
      N170_neu=topoplot(Topo_Emo_Neu, time_lim = c(170, 230),interp_limit = &quot;head&quot;, limits = c(-5,5))+
        ggtitle(&quot;N170 (170-230 ms)&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;neutral&quot;, size=3)

      N170_hap=topoplot(Topo_Emo_Hap, time_lim = c(170, 230),interp_limit = &quot;head&quot;, limits = c(-5,5))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;happy&quot;, size=3)

      N170_ang=topoplot(Topo_Emo_Ang, time_lim = c(170, 230),interp_limit = &quot;head&quot;, limits = c(-5,5))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;angry&quot;, size=3)

    # P3s
      P3_neu=topoplot(Topo_Emo_Neu, time_lim = c(300, 600),interp_limit = &quot;head&quot;,limits = c(-5,10))+
        ggtitle(&quot;P3 (300-600 ms)&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;neutral&quot;, size=3)

      P3_hap=topoplot(Topo_Emo_Hap, time_lim = c(300, 600),interp_limit = &quot;head&quot;,limits = c(-5,10))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;happy&quot;, size=3)

      P3_ang=topoplot(Topo_Emo_Ang, time_lim = c(300, 600),interp_limit = &quot;head&quot;, limits = c(-5,10))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;angry&quot;, size=3)

    # Combine plots
      combine_plots(P1_neu, N170_neu, P3_neu,
                     P1_hap, N170_hap, P3_hap,
                     P1_ang, N170_ang, P3_ang,
                      ncol = 3,
                      caption.text = &quot;Figure XX: Topographical maps of emotion condition&quot;,
                      caption.color = &quot;black&quot;,
                      caption.hjust = 0.5)</code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/ERP_val_topos-1.png" width="1152" /></p>
<p><br></p>
</div>
<div id="p3" class="section level5">
<h5>3.2.1.3 P3</h5>
<p>Similar to P1 and N170, we also tested whether P3 amplitudes were larger for emotional in contrast to neutral faces at “face 1” (See <strong>Figure X A</strong>). The LMM with the best model fit was comprised of random intercepts for participant and stimulus. In line with our hypothesis, angry faces elicited larger amplitudes compared to neutral faces (<span class="math inline">\(\hat{β}\)</span> = 1.67, <em>p</em> &lt;0.05). No difference, however, was found between happy and neutral faces (<span class="math inline">\(\hat{β}\)</span> = 0.71, <em>p</em> = 0.35). Covariates showed no significant results (See <strong>Table XX</strong>).</p>
<p><br></p>
<pre class="r"><code>labels = c(&quot;Intercept&quot;,&quot;Happy vs Neutral&quot;, &quot;Angry vs Neutral&quot;, &quot;Age&quot;, &quot;Working Memory&quot;,&quot;HvsN X ROI&quot;, &quot;AvsN X ROI&quot;)

       # Create table
          tab_model(mod_P1_val.lmer4, mod_N170_val.lmer2, mod_P3_val.lmer4, 
                    pred.labels=labels,
                    show.se=TRUE, show.stat=TRUE, show.ci = FALSE, string.se = &quot;SE&quot;,
                    show.re.var=FALSE, show.obs=FALSE,
                    emph.p = TRUE, dv.labels=c(&quot;P1 Amplitudes&quot;,&quot;N170 Amplitudes&quot;,&quot;P3 Amplitudes&quot;),
                    show.icc = FALSE)</code></pre>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="4" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
P1 Amplitudes
</th>
<th colspan="4" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
N170 Amplitudes
</th>
<th colspan="4" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
P3 Amplitudes
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
SE
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
SE
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  0">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  1">
SE
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  2">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  3">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Intercept
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
12.52
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
11.90
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-7.03
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.67
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-10.56
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
8.04
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
6.92
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Happy vs Neutral
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.99
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.64
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.55
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.121
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.40
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-0.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.843
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.71
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
0.76
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
0.94
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.349
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Angry vs Neutral
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.60
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.65
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
2.46
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>0.014</strong>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.57
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.41
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
1.39
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.164
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
1.67
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
0.77
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
2.17
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
<strong>0.030</strong>
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Age
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.16
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.98
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.18
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.239
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.62
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
0.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.998
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
1.94
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.07
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
1.81
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.070
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Working Memory
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.10
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.922
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.63
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
0.17
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.867
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.20
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
0.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.852
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
HvsN X ROI
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.51
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.57
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-0.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.371
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
AvsN X ROI
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.52
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.59
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-0.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.372
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
28 <sub>ID</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
28 <sub>ID</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
28 <sub>ID</sub>
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
72 <sub>Stim_Type</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
 
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
72 <sub>Stim_Type</sub>
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="4">
0.009 / NA
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="4">
0.001 / 0.061
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="4">
0.014 / 0.110
</td>
</tr>
</table>
<p><br></p>
<p><em>Table XX: Results of LMMs for contrasting emotions</em></p>
<p><br></p>
</div>
</div>
<div id="categorization-effects" class="section level4">
<h4>3.2.2 Categorization effects</h4>
<hr />
<div id="assumption-checks-1" class="section level5 tabset tabset-pills">
<h5>Assumption checks</h5>
<div id="lmm_p1-normality-of-residuals-1" class="section level6">
<h6>LMM_P1: Normality of residuals</h6>
<pre class="r"><code> # Select correct responses
          P1_Cat = subset(All_Subj, Response == 1)    
          
        # Select targets
          P1_Cat = subset(P1_Cat,Group_pt == 2)   
            
        # Prepare fixed factors 
          P1_Cat$ID = as.factor(P1_Cat$ID)
          P1_Cat$Stim_Type = as.factor(P1_Cat$Stim_Type)
  
        # Define novel vs repeated trials
          P1_Cat[P1_Cat$Group_pcic==2,]$Group_pcic = &quot;repeated&quot;
          P1_Cat[P1_Cat$Group_pcic==3,]$Group_pcic = &quot;novel&quot;
        
        # Create factor, get neutral as baseline
          P1_Cat$Group_pcic = factor(P1_Cat$Group_pcic, levels=c(&quot;novel&quot;,&quot;repeated&quot;))
        
        # Set treatment contrast
          (contrasts(P1_Cat$Group_pcic) = contr.sum(2)/2)
  
      # 1) Check properties of DV / residuals 

        # Check which transformation of DV is suitable
          # we have positive and negative single trial values
          # hence: add constant value prior to box-cox
          
          P1_Cat$Trans_P1 = P1_Cat$mean_ROI_P1 + 1 - min(P1_Cat$mean_ROI_P1)
      
        # To make sure residuals follow ND: Calculate box-cox plot
           boxcox(P1_Cat$Trans_P1 ~ P1_Cat$Group_pcic)   </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P1_cat_res-1.png" width="768" /></p>
<pre class="r"><code>        # Visualize normality assumption of residuals (without log transform)
          mod_P1_Cat = lm(Trans_P1 ~ Group_pcic, data=P1_Cat)
          res.mod_P1_Cat = residuals(mod_P1_Cat)
          
          par(mfrow=c(1,2))
          qqpl_mod_P1_Cat = qqPlot(res.mod_P1_Cat, main=&quot;QQplot before transformation&quot;)    
          norm_mod_P1_Cat = plot(density(res.mod_P1_Cat), main=&quot;Density plot before transformation&quot;)  </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P1_cat_res-2.png" width="768" /></p>
<pre class="r"><code>          par(mfrow=c(1,1))</code></pre>
<hr />
</div>
<div id="lmm_p1-random-effect-structure-1" class="section level6">
<h6>LMM_P1: Random effect structure</h6>
<pre class="r"><code>     # 3) Construct full model     
            
        # Add contrast columns
          mm_c =  model.matrix( ~ Group_pcic, P1_Cat) 
        
        # Attach to dataframe
          P1_Cat[,(ncol(P1_Cat)+1):(ncol(P1_Cat)+2)] = mm_c
          names(P1_Cat)[(ncol(P1_Cat)-1):ncol(P1_Cat)] = c(&quot;Mean&quot;,&quot;Nov_Rep&quot;) 
        
        # Build model 
          mod_P1_cat.lmer1 = lmer(mean_ROI_P1 ~ 
                                Nov_Rep + scale(Age) + scale(WM) + 
                                (1 + Nov_Rep||ID) +
                                (1 + Nov_Rep||Stim_Type),
                              data = P1_Cat,
                              control=lmerControl(calc.derivs = FALSE))
        
        # 1st: check how many zero variance terms you got in random effects
          summary(rePCA(mod_P1_cat.lmer1))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                           [,1]     [,2]
## Standard deviation     0.00016 0.000147
## Proportion of Variance 0.54028 0.459720
## Cumulative Proportion  0.54028 1.000000
## 
## $ID
## Importance of components:
##                         [,1]      [,2]
## Standard deviation     0.397 0.0000398
## Proportion of Variance 1.000 0.0000000
## Cumulative Proportion  1.000 1.0000000</code></pre>
<pre class="r"><code>        # 2nd: check which random terms explain the least variance
          print(VarCorr(mod_P1_cat.lmer1),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups      Name        Variance     
##  Stim_Type   Nov_Rep       0.000004580
##  Stim_Type.1 (Intercept)   0.000003897
##  ID          Nov_Rep       0.000000285
##  ID.1        (Intercept)  28.358220635
##  Residual                180.029310668</code></pre>
<pre class="r"><code>        # Likelihood-ratio testing
          
          # ID
            mod_P1_cat.lmer2 = lmer(mean_ROI_P1 ~ 
                                      Nov_Rep + scale(Age) + scale(WM) + 
                                      (1 | ID) +
                                      (1 + Nov_Rep||Stim_Type),
                                    data = P1_Cat,
                                    control=lmerControl(calc.derivs = FALSE))
            
          # Calculate ANOVA
            anova(mod_P1_cat.lmer1, mod_P1_cat.lmer2)</code></pre>
<pre><code>## Data: P1_Cat
## Models:
## mod_P1_cat.lmer2: mean_ROI_P1 ~ Nov_Rep + scale(Age) + scale(WM) + (1 | ID) + (1 + 
## mod_P1_cat.lmer2:     Nov_Rep || Stim_Type)
## mod_P1_cat.lmer1: mean_ROI_P1 ~ Nov_Rep + scale(Age) + scale(WM) + (1 + Nov_Rep || 
## mod_P1_cat.lmer1:     ID) + (1 + Nov_Rep || Stim_Type)
##                  Df  AIC  BIC logLik deviance Chisq Chi Df
## mod_P1_cat.lmer2  8 9464 9505  -4724     9448             
## mod_P1_cat.lmer1  9 9466 9512  -4724     9448     0      1
##                  Pr(&gt;Chisq)
## mod_P1_cat.lmer2           
## mod_P1_cat.lmer1          1</code></pre>
<pre class="r"><code>          # Stim_Type
            mod_P1_cat.lmer3 = lmer(mean_ROI_P1 ~ 
                                      Nov_Rep + scale(Age) + scale(WM) + 
                                      (1 + Nov_Rep|| ID) +
                                      (1 |Stim_Type),
                                    data = P1_Cat,
                                    control=lmerControl(calc.derivs = FALSE))
            
          # Calculate ANOVA
            anova(mod_P1_cat.lmer1, mod_P1_cat.lmer3)</code></pre>
<pre><code>## Data: P1_Cat
## Models:
## mod_P1_cat.lmer3: mean_ROI_P1 ~ Nov_Rep + scale(Age) + scale(WM) + (1 + Nov_Rep || 
## mod_P1_cat.lmer3:     ID) + (1 | Stim_Type)
## mod_P1_cat.lmer1: mean_ROI_P1 ~ Nov_Rep + scale(Age) + scale(WM) + (1 + Nov_Rep || 
## mod_P1_cat.lmer1:     ID) + (1 + Nov_Rep || Stim_Type)
##                  Df  AIC  BIC logLik deviance Chisq Chi Df
## mod_P1_cat.lmer3  8 9464 9505  -4724     9448             
## mod_P1_cat.lmer1  9 9466 9512  -4724     9448     0      1
##                  Pr(&gt;Chisq)
## mod_P1_cat.lmer3           
## mod_P1_cat.lmer1          1</code></pre>
<pre class="r"><code>        # Final model
          mod_P1_cat.lmer4 = lmer(mean_ROI_P1 ~ 
                                      Nov_Rep + scale(Age) + scale(WM) + 
                                      (1|ID) +
                                      (1|Stim_Type),
                                    data = P1_Cat,
                                    control=lmerControl(calc.derivs = FALSE))</code></pre>
<hr />
</div>
<div id="lmm_p1-homoscedasticity-1" class="section level6">
<h6>LMM_P1: Homoscedasticity</h6>
<pre class="r"><code>      # 4) Check homoscedasticity  
        
        # Whether residuals are equally dsitributed along regression line 
          plot(fitted(mod_P1_cat.lmer4), residuals(mod_P1_cat.lmer4))
          abline(0, 0)       </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P1_cat_homosk-1.png" width="768" /></p>
<hr />
</div>
<div id="lmm_n170-normality-of-residuals-1" class="section level6">
<h6>LMM_N170: Normality of residuals</h6>
<pre class="r"><code>   # Select targets
          N170_Cat = subset(All_Subj, Group_pt == 2) 
        
        # Define novel vs repeated trials
          N170_Cat[N170_Cat$Group_pcic==2,]$Group_pcic = &quot;repeated&quot;
          N170_Cat[N170_Cat$Group_pcic==3,]$Group_pcic = &quot;novel&quot;
        
        # Separate data in left and right hemisphere
          N170_Cat = gather (N170_Cat, Elect_site, N170_Amplitude, mean_ROI_N170l:mean_ROI_N170r, factor_key = TRUE)
          N170_Cat$Elect_site = as.character(N170_Cat$Elect_site)
        
        # Add variable name
          N170_Cat$Elect_site[N170_Cat$Elect_site == &quot;mean_ROI_N170l&quot;] = &#39;left&#39;
          N170_Cat$Elect_site[N170_Cat$Elect_site == &quot;mean_ROI_N170r&quot;] = &quot;right&quot;
        
        # Set contrast for elect site
          N170_Cat$Elect_site = factor(N170_Cat$Elect_site)
          contrasts(N170_Cat$Elect_site) = contr.sum(2)/2
        
        # Factor random factors 
          N170_Cat$ID = as.factor(N170_Cat$ID)
          N170_Cat$Stim_Type = as.factor(N170_Cat$Stim_Type)

        # Create factor, get neutral as baseline
          N170_Cat$Group_pcic = factor(N170_Cat$Group_pcic, levels=c(&quot;novel&quot;,&quot;repeated&quot;))
        
        # Set treatment contrast
          (contrasts(N170_Cat$Group_pcic) = contr.sum(2)/2)
        
        
      # 1) Check properties of DV / residuals 
        
        # Check which transformation of DV is suitable
          # we have positive and negative single trial values
          # hence: add constant value prior to box-cox
          
          N170_Cat$Trans_N170 = N170_Cat$N170_Amplitude + 1 - min(N170_Cat$N170_Amplitude)

        # To make sure residuals follow ND: Calculate box-cox plot
           boxcox(N170_Cat$Trans_N170 ~ N170_Cat$Group_pcic)   </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/N170_cat_res-1.png" width="768" /></p>
<pre class="r"><code>        # Visualize normality assumption of residuals (without log transform)
          mod_N170_Cat = lm(Trans_N170 ~ Group_pcic, data=N170_Cat)
          res.mod_N170_Cat = residuals(mod_N170_Cat)
          
          par(mfrow=c(1,2))
          qqpl_mod_N170_Cat = qqPlot(res.mod_N170_Cat, main=&quot;QQplot before transformation&quot;)    
          norm_mod_N170_Cat = plot(density(res.mod_N170_Cat), main=&quot;Density plot before transformation&quot;)  </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/N170_cat_res-2.png" width="768" /></p>
<pre class="r"><code>          par(mfrow=c(1,1))            </code></pre>
<hr />
</div>
<div id="lmm_n170-random-effect-structure-1" class="section level6">
<h6>LMM_N170: Random effect structure</h6>
<pre class="r"><code>      # 3) Construct full model
              
        # Add contrast columns
          mm_c =  model.matrix( ~ Group_pcic + Elect_site + Condition*Elect_site, N170_Cat) 
        
        # Attach to dataframe
          N170_Cat[,(ncol(N170_Cat)+1):(ncol(N170_Cat)+4)] = mm_c
          names(N170_Cat)[(ncol(N170_Cat)-3):ncol(N170_Cat)] = c(&quot;Mean&quot;,&quot;Nov_Rep&quot;,&quot;Elect_site&quot;,&quot;Nov_RepxElect_site&quot;) 
        
        # Get model 
          mod_N170_cat.lmer1 = lmer(N170_Amplitude ~ 
                                  Nov_Rep + Nov_RepxElect_site + Elect_site + scale(Age) + scale(WM) + 
                                  (1 + Nov_Rep + Nov_RepxElect_site + Elect_site||ID) +
                                  (1 + Nov_Rep + Nov_RepxElect_site + Elect_site||Stim_Type),
                                data = N170_Cat,
                                control=lmerControl(calc.derivs = FALSE))
        
        # 1st: check how many zero variance terms you got in random effects
          summary(rePCA(mod_N170_cat.lmer1))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                         [,1]     [,2]      [,3] [,4] [,5]
## Standard deviation     0.111 0.000107 0.0000606    0    0
## Proportion of Variance 1.000 0.000000 0.0000000    0    0
## Cumulative Proportion  1.000 1.000000 1.0000000    1    1
## 
## $ID
## Importance of components:
##                         [,1]  [,2]      [,3] [,4] [,5]
## Standard deviation     0.298 0.270 0.0000665    0    0
## Proportion of Variance 0.549 0.451 0.0000000    0    0
## Cumulative Proportion  0.549 1.000 1.0000000    1    1</code></pre>
<pre class="r"><code>        # 2nd: check which random terms explain the least variance
          print(VarCorr(mod_N170_cat.lmer1),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups      Name               Variance      Corr
##  Stim_Type   Elect_siteleft       0.000000000     
##              Elect_siteright      1.803620747  NaN
##  Stim_Type.1 Nov_RepxElect_site   0.000000000     
##  Stim_Type.2 Nov_Rep              0.000001675     
##  Stim_Type.3 (Intercept)          0.000000534     
##  ID          Elect_siteleft       0.000000000     
##              Elect_siteright     12.919710957  NaN
##  ID.1        Nov_RepxElect_site   0.000000642     
##  ID.2        Nov_Rep              0.000000000     
##  ID.3        (Intercept)         10.596324489     
##  Residual                       145.162934619</code></pre>
<pre class="r"><code>        # Improved model 
          mod_N170_cat.lmer2 = lmer(N170_Amplitude ~ 
                                      Nov_Rep + Nov_RepxElect_site + Elect_site + scale(Age) + scale(WM) + 
                                      (1 + Elect_site||ID),
                                    data = N170_Cat,
                                    control=lmerControl(calc.derivs = FALSE))
          
        # Re-check variances
          summary(rePCA(mod_N170_cat.lmer2))</code></pre>
<pre><code>## $ID
## Importance of components:
##                         [,1]  [,2]  [,3]
## Standard deviation     0.309 0.212 0.153
## Proportion of Variance 0.582 0.275 0.143
## Cumulative Proportion  0.582 0.857 1.000</code></pre>
<pre class="r"><code>          print(VarCorr(mod_N170_cat.lmer2),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups   Name            Variance Corr
##  ID       (Intercept)       3.42       
##  ID.1     Elect_siteleft    8.25       
##           Elect_siteright  12.24   0.31
##  Residual                 145.99</code></pre>
<pre class="r"><code>        # Likelihood ratio testing 
          
          # ID
            mod_N170_cat.lmer3 = lmer(N170_Amplitude ~ 
                                      Nov_Rep + Nov_RepxElect_site + Elect_site + scale(Age) + scale(WM) + 
                                      (1 |ID),
                                    data = N170_Cat,
                                    control=lmerControl(calc.derivs = FALSE))

          # Calculate ANOVA
            anova(mod_N170_cat.lmer2 ,mod_N170_cat.lmer3 )</code></pre>
<pre><code>## Data: N170_Cat
## Models:
## mod_N170_cat.lmer3: N170_Amplitude ~ Nov_Rep + Nov_RepxElect_site + Elect_site + 
## mod_N170_cat.lmer3:     scale(Age) + scale(WM) + (1 | ID)
## mod_N170_cat.lmer2: N170_Amplitude ~ Nov_Rep + Nov_RepxElect_site + Elect_site + 
## mod_N170_cat.lmer2:     scale(Age) + scale(WM) + (1 + Elect_site || ID)
##                    Df   AIC   BIC logLik deviance Chisq Chi Df
## mod_N170_cat.lmer3  8 46594 46648 -23289    46578             
## mod_N170_cat.lmer2 11 46523 46597 -23251    46501  76.9      3
##                             Pr(&gt;Chisq)    
## mod_N170_cat.lmer3                        
## mod_N170_cat.lmer2 &lt;0.0000000000000002 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>        # Final model
          mod_N170_cat.lmer4 = lmer(N170_Amplitude ~ 
                                      Nov_Rep + Nov_RepxElect_site + Elect_site + scale(Age) + scale(WM) + 
                                      (1 + Elect_site||ID),
                                      data = N170_Cat,
                                      control=lmerControl(calc.derivs = FALSE))</code></pre>
<hr />
</div>
<div id="lmm_n170-homoscedasticity-1" class="section level6">
<h6>LMM_N170: Homoscedasticity</h6>
<pre class="r"><code>      # 4) Check homoscedasticity  
        
        # Whether residuals are equally dsitributed along regression line 
          plot(fitted(mod_N170_cat.lmer4), residuals(mod_N170_cat.lmer4))
          abline(0, 0)         </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/N170_cat_homosk-1.png" width="768" /></p>
<hr />
</div>
<div id="lmm_p3-normality-of-residuals-1" class="section level6">
<h6>LMM_P3: Normality of residuals</h6>
<pre class="r"><code>#  Build model &amp; check assumptions -----------------------------------------
        
        # Correct responses
          P3_Cat = subset(All_Subj, Response == 1)
  
        # Factor random factors 
          P3_Cat$ID = as.factor(P3_Cat$ID)
          P3_Cat$Stim_Type = as.factor(P3_Cat$Stim_Type)
          
        # Select targets
          P3_Cat = subset(P3_Cat,Group_pt == 2) 
  
        # Define novel vs repeated trials
          P3_Cat[P3_Cat$Group_pcic==2,]$Group_pcic = &quot;repeated&quot;
          P3_Cat[P3_Cat$Group_pcic==3,]$Group_pcic = &quot;novel&quot;
  
        # Create factor, get neutral as baseline
          P3_Cat$Group_pcic = factor(P3_Cat$Group_pcic, levels=c(&quot;novel&quot;,&quot;repeated&quot;))
  
        # Set treatment contrast
          contrasts(P3_Cat$Group_pcic) = contr.sum(2)/2
        
      # 1) Check properties of DV / residuals 
        
        # Check which transformation of DV is suitable
          # we have positive and negative single trial values
          # hence: add constant value prior to box-cox
          
          P3_Cat$Trans_P3 = P3_Cat$mean_ROI_P3 + 1 - min(P3_Cat$mean_ROI_P3)
      
        # To make sure residuals follow ND: Calculate box-cox plot
           boxcox(P3_Cat$Trans_P3 ~ P3_Cat$Group_pcic)   </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P3_cat_res-1.png" width="768" /></p>
<pre class="r"><code>        # Visualize normality assumption of residuals (without log transform)
          mod_P3_Cat = lm(Trans_P3 ~ Group_pcic, data=P3_Cat)
          res.mod_P3_Cat = residuals(mod_P3_Cat)
          
          par(mfrow=c(1,2))
          qqpl_mod_P3_Cat = qqPlot(res.mod_P3_Cat, main=&quot;QQplot before transformation&quot;)    
          norm_mod_P3_Cat = plot(density(res.mod_P3_Cat), main=&quot;Density plot before transformation&quot;)  </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P3_cat_res-2.png" width="768" /></p>
<pre class="r"><code>          par(mfrow=c(1,1))</code></pre>
<hr />
</div>
<div id="lmm_p3-random-effect-structure-1" class="section level6">
<h6>LMM_P3: Random effect structure</h6>
<pre class="r"><code>    # 3) Construct full model  
            
        # Add contrast columns
          mm_c =  model.matrix( ~ Group_pcic, P3_Cat) 
        
        # Attach to dataframe
          P3_Cat[,(ncol(P3_Cat)+1):(ncol(P3_Cat)+2)] = mm_c
          names(P3_Cat)[(ncol(P3_Cat)-1):ncol(P3_Cat)] = c(&quot;Mean&quot;,&quot;Nov_Rep&quot;) 
        
        # Get model 
          mod_P3_cat.lmer1 = lmer(mean_ROI_P3 ~ 
                                Nov_Rep + scale(Age) + scale(WM) + 
                                (1 + Nov_Rep||ID) +
                                (1 + Nov_Rep||Stim_Type),
                              data = P3_Cat,
                              control=lmerControl(calc.derivs = FALSE))
        
        # 1st: check how many zero variance terms you got in random effects
          summary(rePCA(mod_P3_cat.lmer1))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                        [,1] [,2]
## Standard deviation     0.05    0
## Proportion of Variance 1.00    0
## Cumulative Proportion  1.00    1
## 
## $ID
## Importance of components:
##                         [,1]  [,2]
## Standard deviation     0.408 0.164
## Proportion of Variance 0.862 0.139
## Cumulative Proportion  0.862 1.000</code></pre>
<pre class="r"><code>        # 2nd: check which random terms explain the least variance
          print(VarCorr(mod_P3_cat.lmer1),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups      Name        Variance
##  Stim_Type   Nov_Rep       0.577 
##  Stim_Type.1 (Intercept)   0.000 
##  ID          Nov_Rep       6.177 
##  ID.1        (Intercept)  38.421 
##  Residual                230.366</code></pre>
<pre class="r"><code>        # Improved model
          mod_P3_cat.lmer2 = lmer(mean_ROI_P3 ~ 
                                Nov_Rep + scale(Age) + scale(WM) + 
                                (1 + Nov_Rep||ID) +
                                (0 + Nov_Rep|Stim_Type),
                              data = P3_Cat,
                              control=lmerControl(calc.derivs = FALSE))
          
        # Re-check the model  
          summary(rePCA(mod_P3_cat.lmer2))</code></pre>
<pre><code>## $Stim_Type
## Importance of components:
##                          [,1]
## Standard deviation     0.0493
## Proportion of Variance 1.0000
## Cumulative Proportion  1.0000
## 
## $ID
## Importance of components:
##                         [,1]  [,2]
## Standard deviation     0.408 0.164
## Proportion of Variance 0.861 0.139
## Cumulative Proportion  0.861 1.000</code></pre>
<pre class="r"><code>          print(VarCorr(mod_P3_cat.lmer2),comp = &quot;Variance&quot;)</code></pre>
<pre><code>##  Groups    Name        Variance
##  Stim_Type Nov_Rep       0.561 
##  ID        Nov_Rep       6.180 
##  ID.1      (Intercept)  38.412 
##  Residual              230.370</code></pre>
<pre class="r"><code>        # Likelhood ratio testing
          
          # ID
            mod_P3_cat.lmer3 = lmer(mean_ROI_P3 ~ 
                                  Nov_Rep + scale(Age) + scale(WM) + 
                                  (1|ID) +
                                  (0 + Nov_Rep|Stim_Type),
                                data = P3_Cat,
                                control=lmerControl(calc.derivs = FALSE))
            
          # Calculate ANOVA
            anova(mod_P3_cat.lmer2,mod_P3_cat.lmer3)</code></pre>
<pre><code>## Data: P3_Cat
## Models:
## mod_P3_cat.lmer3: mean_ROI_P3 ~ Nov_Rep + scale(Age) + scale(WM) + (1 | ID) + (0 + 
## mod_P3_cat.lmer3:     Nov_Rep | Stim_Type)
## mod_P3_cat.lmer2: mean_ROI_P3 ~ Nov_Rep + scale(Age) + scale(WM) + (1 + Nov_Rep || 
## mod_P3_cat.lmer2:     ID) + (0 + Nov_Rep | Stim_Type)
##                  Df  AIC  BIC logLik deviance Chisq Chi Df
## mod_P3_cat.lmer3  7 9759 9794  -4873     9745             
## mod_P3_cat.lmer2  8 9760 9801  -4872     9744  0.51      1
##                  Pr(&gt;Chisq)
## mod_P3_cat.lmer3           
## mod_P3_cat.lmer2       0.47</code></pre>
<pre class="r"><code>          # Stim_Type
            mod_P3_cat.lmer4 = lmer(mean_ROI_P3 ~ 
                                      Nov_Rep + scale(Age) + scale(WM) + 
                                      (1|ID) +
                                      (1|Stim_Type),
                                    data = P3_Cat,
                                    control=lmerControl(calc.derivs = FALSE))
            
           # Calculate ANOVA
            anova(mod_P3_cat.lmer2,mod_P3_cat.lmer4)</code></pre>
<pre><code>## Data: P3_Cat
## Models:
## mod_P3_cat.lmer4: mean_ROI_P3 ~ Nov_Rep + scale(Age) + scale(WM) + (1 | ID) + (1 | 
## mod_P3_cat.lmer4:     Stim_Type)
## mod_P3_cat.lmer2: mean_ROI_P3 ~ Nov_Rep + scale(Age) + scale(WM) + (1 + Nov_Rep || 
## mod_P3_cat.lmer2:     ID) + (0 + Nov_Rep | Stim_Type)
##                  Df  AIC  BIC logLik deviance Chisq Chi Df
## mod_P3_cat.lmer4  7 9759 9794  -4873     9745             
## mod_P3_cat.lmer2  8 9760 9801  -4872     9744  0.51      1
##                  Pr(&gt;Chisq)
## mod_P3_cat.lmer4           
## mod_P3_cat.lmer2       0.47</code></pre>
<pre class="r"><code>        # Final model
          mod_P3_cat.lmer4 = lmer(mean_ROI_P3 ~ 
                              Nov_Rep + scale(Age) + scale(WM) + 
                              (1|ID) +
                              (0 + Nov_Rep|Stim_Type),
                              data = P3_Cat,
                              control=lmerControl(calc.derivs = FALSE))</code></pre>
<hr />
</div>
<div id="lmm_p3-homoscedasticity-1" class="section level6">
<h6>LMM_P3: Homoscedasticity</h6>
<pre class="r"><code>      # 4) Check homoscedasticity  
          plot(fitted(mod_P3_cat.lmer4), residuals(mod_P3_cat.lmer4))
          abline(0, 0)    </code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/P3_cat_homosk-1.png" width="768" /></p>
<hr />
</div>
</div>
<div id="p1-1" class="section level5">
<h5>3.2.2.1 P1</h5>
<p>We evaluated whether trials in which a novel emotion was presented as “face 2” would elicit larger P1 amplitudes compared to trials in which the same emotion was repeated (See <strong>Figure X A</strong>). The best-fitted model included stimulus and participant as random intercepts. In contrast to our hypothesis, we did not find a difference between trials with novel in contrast to repeated emotions (<span class="math inline">\(\hat{β}\)</span> = -1.54, <em>p</em> = 0.08). None of the covariates reached significance (age: <span class="math inline">\(\hat{β}\)</span> = 1.89, <em>p</em> = 0.1; working memory: <span class="math inline">\(\hat{β}\)</span> = 0.39, <em>p</em> = 0.73).</p>
<pre class="r"><code>  # Load &quot;face 2&quot; data
        Target_data = read.csv(&quot;./data/ERPs/ROI_P1_target.csv&quot;,header = TRUE)

      # De-select participants
        Target_data = Target_data[with(Target_data, !(Target_data$ID==&quot;05&quot;)), ]

      # Select time window of interest
        Target_data = Target_data[(Target_data$Time &gt;= -200)&amp; (Target_data$Time &lt;= 600),]

      # Rename values of target condition
        Target_data$Condition[Target_data$Condition == 1]=&#39;repeated&#39;;
        Target_data$Condition[Target_data$Condition == 2]=&#39;novel&#39;;
        Target_data$Condition[Target_data$Condition == 3]=&#39;prime&#39;;
        Target_data$Condition[Target_data$Condition == 4]=&#39;c_happy&#39;;
        Target_data$Condition[Target_data$Condition == 5]=&#39;c_neutral&#39;;
        Target_data$Condition[Target_data$Condition == 6]=&#39;c_angry&#39;;
        Target_data$Condition[Target_data$Condition == 7]=&#39;ic_happy&#39;;
        Target_data$Condition[Target_data$Condition == 8]=&#39;ic_neutral&#39;;
        Target_data$Condition[Target_data$Condition == 9]=&#39;ic_angry&#39;;

      # Plot ERP trajectory for P1/P3
        Target_data_icc = Target_data[(Target_data$Condition == &#39;repeated&#39;)  | (Target_data$Condition == &#39;novel&#39;),]

        P1_cat_traj = ggplot(Target_data_icc,aes(Time,ROI_Average))+
            theme(panel.background = element_blank(),panel.border = element_rect(colour = &quot;grey&quot;, fill=NA, size=2),
                  axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))+
            stat_summary(fun.y = mean,geom = &quot;line&quot;, size = 1, linetype = &quot;solid&quot;,aes(colour= Condition))+
            scale_colour_manual(values = c(&quot;gray32&quot;,&quot;#6AC2FF&quot;))+
            ggtitle(&quot;P1 &amp; P3&quot;) +
            #theme(axis.title.x=element_blank())+      # turn off x-axis title
            #theme(axis.title.y=element_blank())+      # turn off y-axis title
            theme(legend.position=&quot;bottom&quot;)+            # turn off legend
            labs(x = &quot;\ntime (ms)&quot;,y = expression(paste(&quot;Mean amplitude across ROI [&quot;,mu,&quot;V]&quot;)),colour = &quot;&quot;)+
            coord_cartesian(ylim=c(-2, 16),xlim=c(-100,600)) +
            scale_y_continuous(breaks=seq(-2,16,2))+
            scale_x_continuous(breaks=seq(-100,600,100))+
            geom_vline(xintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot; )+
            geom_hline(yintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot;)


# LEFT HEMISPHERE: N170

        Target_data_l = read.csv(&quot;./data/ERPs/left_ROI_N170_target.csv&quot;,header = TRUE)
        Target_data_r = read.csv(&quot;./data/ERPs/right_ROI_N170_target.csv&quot;,header = TRUE)

      # De-select participants
        Target_data_l = Target_data_l[with(Target_data_l, !(Target_data_l$ID==&quot;05&quot;)), ]
        Target_data_r = Target_data_r[with(Target_data_r, !(Target_data_r$ID==&quot;05&quot;)), ]

      # Select time window of interest
        Target_data_l = Target_data_l[(Target_data_l$Time &gt;= -200)&amp; (Target_data_l$Time &lt;= 1000),]

      # Rename conditions
        Target_data_l$Condition[Target_data_l$Condition == 1]=&#39;repeated&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 2]=&#39;novel&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 3]=&#39;prime&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 4]=&#39;c_happy&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 5]=&#39;c_neutral&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 6]=&#39;c_angry&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 7]=&#39;ic_happy&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 8]=&#39;ic_neutral&#39;;
        Target_data_l$Condition[Target_data_l$Condition == 9]=&#39;ic_angry&#39;;

      # Select conditions of interest
        Target_data_icc_l = Target_data_l[(Target_data_l$Condition == &#39;repeated&#39;)  | (Target_data_l$Condition == &#39;novel&#39;),]

      # Plot N170 left hemisphere trajectory
        N170l_cat_traj = ggplot(Target_data_icc_l,aes(Time,ROI_Average))+
          theme(panel.background = element_blank(),panel.border = element_rect(colour = &quot;grey&quot;, fill=NA, size=2),
                axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))+
          stat_summary(fun.y = mean,geom = &quot;line&quot;, size = 1,linetype = &quot;solid&quot;,aes(colour= Condition))+
          scale_colour_manual(values = c(&quot;gray32&quot;,&quot;#6AC2FF&quot;))+
          ggtitle(&quot;Left Hemisphere: 170&quot;) +
          #theme(axis.title.x=element_blank())+      # turn off x-axis title
          #theme(axis.title.y=element_blank())+      # turn off y-axis title
          theme(legend.position=&quot;bottom&quot;)+            # turn off legend
          labs(x = &quot;\ntime (ms)&quot;,y = expression(paste(&quot;Mean amplitude across ROI [&quot;,mu,&quot;V]&quot;)),colour = &quot;&quot;)+
          coord_cartesian(ylim=c(-6, 6),xlim=c(-100,600)) +
          scale_y_continuous(breaks=seq(-6,6,2))+
          scale_x_continuous(breaks=seq(-100,600,100))+
          geom_vline(xintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot; )+
          geom_hline(yintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot;)

# RIGHT HEMISPHERE: N170

        # Select time window of interest
          Target_data_r = Target_data_r[(Target_data_r$Time &gt;= -200)&amp; (Target_data_r$Time &lt;= 1000),]

        # Rename conditions
          Target_data_r$Condition[Target_data_r$Condition == 1]=&#39;repeated&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 2]=&#39;novel&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 3]=&#39;prime&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 4]=&#39;c_happy&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 5]=&#39;c_neutral&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 6]=&#39;c_angry&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 7]=&#39;ic_happy&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 8]=&#39;ic_neutral&#39;;
          Target_data_r$Condition[Target_data_r$Condition == 9]=&#39;ic_angry&#39;;

        # Select conditions of interest
          Target_data_icc_r = Target_data_r[(Target_data_r$Condition == &#39;repeated&#39;) | (Target_data_r$Condition == &#39;novel&#39;),]

        # Plot N170 right hemisphere trajectory
          N170r_cat_traj = ggplot(Target_data_icc_r,aes(Time,ROI_Average))+
            theme(panel.background = element_blank(),panel.border = element_rect(colour = &quot;grey&quot;, fill=NA, size=2),
                  axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))+
            stat_summary(fun.y = mean,geom = &quot;line&quot;,size = 1 ,linetype = &quot;solid&quot;,aes(colour= Condition))+
            scale_colour_manual(values = c(&quot;gray32&quot;,&quot;#6AC2FF&quot;))+
            ggtitle(&quot;Right Hemisphere: N170&quot;) +
            #theme(axis.title.x=element_blank())+      # turn off x-axis title
            #theme(axis.title.y=element_blank())+      # turn off y-axis title
            theme(legend.position=&quot;bottom&quot;)+          # turn off legend
            labs(x = &quot;\ntime (ms)&quot;,y = expression(paste(&quot;Mean amplitude across ROI [&quot;,mu,&quot;V]&quot;)),colour = &quot;&quot;)+
            coord_cartesian(ylim=c(-6,6),xlim=c(-100,600)) +
            scale_y_continuous(breaks=seq(-6,6,2))+
            scale_x_continuous(breaks=seq(-100,600,100))+
            geom_vline(xintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot; )+
            geom_hline(yintercept = 0,linetype = &quot;dashed&quot;,colour=&quot;grey&quot;)

# Combine plots
      combine_plots(P1_cat_traj, N170l_cat_traj, N170r_cat_traj,
                               ncol = 3, nrow=1,
                               labels = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;),
                               caption.color = &quot;black&quot;,
                               caption.vjust = 0,
                               caption.hjust = 1.3,
                               caption.text = &quot;Figure XX: ERP trajectories for category effects&quot;)</code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/ERP_cat_traj-1.png" width="768" /></p>
<p><br></p>
</div>
<div id="n170-1" class="section level5">
<h5>3.2.2.2 N170</h5>
<p>For the analysis N170 amplitude differences for trials with novel in contrast to repeated emotions, we included hemisphere (left vs right) as additional fixed effect factor as well as the interaction between hemisphere and and novelty (See <strong>Figure X B,C</strong>). The LMM with the best fit included a random intercept for participant with a random slope for hemisphere. In contrast to our hypothesis, we did not find a significant effect of novelty (<span class="math inline">\(\hat{β}\)</span> = -0.7, <em>p</em> = 0.29). Neither the main effect of hemisphere (<span class="math inline">\(\hat{β}\)</span> = 1.33, <em>p</em> = 0.1) nor the interaction of hemisphere with novelty was significant (<span class="math inline">\(\hat{β}\)</span> = 0.15, <em>p</em> = 0.44). Age as a covariate was not significant (<span class="math inline">\(\hat{β}\)</span> = -0.47, <em>p</em> = 0.62). The covariate working memory did not reach significance (<span class="math inline">\(\hat{β}\)</span> = 0.53, <em>p</em> = 0.4).</p>
<p><br></p>
<pre class="r"><code># Load topography information
      Topo_Cat = read.csv(file=&quot;./data/ERPs/ERPs_Topo_Categorization.csv&quot;, header=TRUE, sep=&quot;,&quot;)

      Topo_Cat = Topo_Cat[with(Topo_Cat, !(Topo_Emo$ID==5)), ]

    # Re-name to fit topoplot function
      names(Topo_Cat)[names(Topo_Cat) == &quot;Time&quot;] = &quot;time&quot;

    # Change from wide to long format for electrodes
      Topo_Cat = gather(Topo_Cat, electrode, amplitude, Fp1:Oz, factor_key=TRUE)

    # Rename A1/A2
      names(Topo_Cat)[names(Topo_Cat) == &quot;A1&quot;] &lt;- &quot;TP9&quot;
      names(Topo_Cat)[names(Topo_Cat) == &quot;A2&quot;] &lt;- &quot;TP10&quot;

    # Plot topoplots for repeated trials
      Topo_Cat_Rep = subset(Topo_Cat, Condition == 10)

    # Plot topoplots for novel trials
      Topo_Cat_Nov = subset(Topo_Cat, Condition == 11)

    # P1s
      P1_rep=topoplot(Topo_Cat_Rep, time_lim = c(80, 120),interp_limit = &quot;head&quot;, limits = c(-5,20))+
        ggtitle(&quot;P1 (80-120 ms)&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;repeat&quot;, size=3)

      P1_nov=topoplot(Topo_Cat_Nov, time_lim = c(80, 120),interp_limit = &quot;head&quot;, limits = c(-5,20))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;novel&quot;, size=3)

    # N170s
      N170_rep=topoplot(Topo_Cat_Rep, time_lim = c(170, 230),interp_limit = &quot;head&quot;, limits = c(-5,5))+
        ggtitle(&quot;N170 (170-230 ms)&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;repeat&quot;, size=3)

      N170_nov=topoplot(Topo_Cat_Nov, time_lim = c(170, 230),interp_limit = &quot;head&quot;, limits = c(-5,5))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;novel&quot;, size=3)

    # P3s
      P3_rep=topoplot(Topo_Cat_Rep, time_lim = c(300, 600),interp_limit = &quot;head&quot;, limits = c(-10,15))+
        ggtitle(&quot;P3 (300-600 ms)&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;repeat&quot;, size=3)

      P3_nov=topoplot(Topo_Cat_Nov, time_lim = c(300, 600),interp_limit = &quot;head&quot;, limits = c(-10,15))+
        ggtitle(&quot;&quot;)+
        theme(plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;))+
        annotate(geom=&quot;text&quot;, x=-1.05, y=-1, label=&quot;novel&quot;, size=3)

    # Combine plots
      combine_plots(P1_rep, N170_rep, P3_rep,
                               P1_nov, N170_nov, P3_nov,
                               ncol = 3, nrow=2,
                               caption.text = &quot;Figure XX: Topographical maps of category condition&quot;,
                               caption.color = &quot;black&quot;,
                               caption.vjust = -1,
                               caption.hjust = 0.5)</code></pre>
<p><img src="R_Script_3_ERP_measures_files/figure-html/ERP_cat_topos-1.png" width="960" /></p>
</div>
<div id="p3-1" class="section level5">
<h5>3.2.2.3 P3</h5>
<p>We tested whether novel “face 2” trials would elicit larger P3 amplitudes compared to repeated “face 2” trials (See <strong>Figure X A</strong>). The best-fitting LMM was comprised of a random intercept for participant and a random slope for novelty with no random intercept for stimulus (See <strong>Table XX</strong>). We did not find an effect of novelty (<span class="math inline">\(\hat{β}\)</span> = 0.09, <em>p</em> = 0.93), nor did any of the covariates reach significance (age: <span class="math inline">\(\hat{β}\)</span> = 1.71, <em>p</em> = 0.19; working memory: <span class="math inline">\(\hat{β}\)</span> = 0.08, <em>p</em> = 0.95).</p>
<pre class="r"><code>labels = c(&quot;Intercept&quot;,&quot;Novel vs Repeated&quot;, &quot;Age&quot;, &quot;Working Memory&quot;,&quot;NvsR X ROI&quot;, &quot;ROI&quot;)

       # Create table
          tab_model(mod_P1_cat.lmer4, mod_N170_cat.lmer4, mod_P3_cat.lmer4, 
                    pred.labels=labels,
                    show.se=TRUE, show.stat=TRUE, show.ci = FALSE, string.se = &quot;SE&quot;,
                    show.re.var=FALSE, show.obs=FALSE,
                    emph.p = TRUE, dv.labels=c(&quot;P1 Amplitudes&quot;,&quot;N170 Amplitudes&quot;,&quot;P3 Amplitudes&quot;),
                    show.icc = FALSE)</code></pre>
<table style="border-collapse:collapse; border:none;">
<tr>
<th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; ">
 
</th>
<th colspan="4" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
P1 Amplitudes
</th>
<th colspan="4" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
N170 Amplitudes
</th>
<th colspan="4" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; ">
P3 Amplitudes
</th>
</tr>
<tr>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; ">
Predictors
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
SE
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  ">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col7">
SE
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col8">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  col9">
p
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  0">
Estimates
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  1">
SE
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  2">
Statistic
</td>
<td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  3">
p
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Intercept
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
16.83
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
15.42
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
<strong>&lt;0.001
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-7.76
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
1.39
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-5.56
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
<strong>&lt;0.001
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
10.95
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
8.65
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
<strong>&lt;0.001
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Novel vs Repeated
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-1.54
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.87
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-1.77
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.076
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.70
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.66
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-1.05
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.294
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.00
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
0.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.925
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Age
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.89
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.09
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.73
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.084
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
-0.47
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.62
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
-0.76
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.446
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
1.71
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.27
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
1.35
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.176
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
Working Memory
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.39
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.11
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.35
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.728
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.53
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.62
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
0.85
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.394
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
0.08
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
1.29
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
0.06
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
0.953
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
NvsR X ROI
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
0.15
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.19
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
0.77
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.440
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; ">
ROI
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  ">
1.33
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col7">
0.78
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col8">
1.70
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  col9">
0.089
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  0">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  1">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  2">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  3">
</td>
</tr>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
N
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
28 <sub>ID</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
28 <sub>ID</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
28 <sub>ID</sub>
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;">
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
40 <sub>Stim_Type</sub>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
 
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="4">
40 <sub>Stim_Type</sub>
</td>
<tr>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;">
Marginal R<sup>2</sup> / Conditional R<sup>2</sup>
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="4">
0.025 / NA
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="4">
0.006 / 0.029
</td>
<td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="4">
0.011 / 0.152
</td>
</tr>
</table>
<p><br></p>
<p><em>Table XX: Results of LMMs for contrasting novel and repeated trials</em></p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4,h5",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
