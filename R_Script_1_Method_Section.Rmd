---
title: "Method section"
output: 
  html_document:
    css: styles.css
    code_folding: hide
    toc: false  
---

<!-- Set up workspace -->

```{r setup, include = FALSE, message = FALSE, warning = FALSE}

# Set general settings for Markdown file 
  knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, results = FALSE)

# Set root file
 knitr::opts_knit$set(root.dir = 'C:/Users/naumasan/Documents/Data_Analysis/2018_Pilotierung_Adlershof/Electrophysiological_Correlates_of Decoding_Emotional_Face_Expressions_in_Children')
  
# Swipe environment
  rm(list=ls())
  
# Set libraries
  library(dplyr)
  library(eeptools)
  library(EnvStats)
  library(expss)
  library(ez)
  library(ggplot2)
  library(gridExtra)
  library(gvlma)
  library(Hmisc)
  library(htmlTable)
  library(nlme)
  library(lattice)
  library(lme4)
  library(lmerTest)
  library(MASS)
  library(pastecs)
  library(plyr)
  library(psych)
  library(readr)
  library(reshape2)
  library(RColorBrewer)
  library(Rmisc)
  library(rowr)
  library(sjPlot)
  library(sjmisc)
  library(sjlabelled)
  library(stringr)
  library(table1)
  library(tidyverse)
  library(tidyr)
  library(XLConnect)
  library(XLConnectJars)
  
# Round to 2 digits   
  options(digits=2)
  
```

<br>

### 2.1 Participants 

```{r age_gender_attr_rate}

# Load questionnaire data
  qn_data = readWorksheetFromFile("./data/QN_Data.xlsx", 
                             sheet = "QN_data", 
                             startCol = 1,
                             endCol = 0) 

# De-select participants 
  # 5 = ERP components not visible 
  qn_data = qn_data[with(qn_data, !(qn_data$ID=="5")), ]

# Define N/A data
  qn_data[qn_data==-99] = NA


# Get length of data frame

  ntotal = 33
  num_part = nrow(qn_data) 
  
# Calculate attrition rate 
  attr_rate = 100-(nrow(qn_data)*100)/ntotal 


# Extract age from birth/test date
# Needs to be numeric in order to create a table
  qn_data$age = as.numeric(cbind(age_calc(as.Date(qn_data$birth_date),
                                          as.Date(qn_data$test_date), units = "years")))

# Calculate mean 
  age_mean = mean(qn_data$age)

# Calculate SD
  age_sd = sd(qn_data$age)
  
  
# Re-code gender
  qn_data$sex[qn_data$sex == 1] = "Male"
  qn_data$sex[qn_data$sex == 2] = "Female"

# Count "female" instances 
  fem = sum(str_count(qn_data$sex, pattern = "Female"))
  mal = num_part - fem

  
```

<br>


#### Table XX

```{r table_descr, results = TRUE}

# Calculate Winkler-Index 

  # Create Winkler Index 
  
    # For the Winkler Index, one awards points for income, occupation and education level of each
    # parent. Points range from 1-5. These points are added up. The maximum value would be 15 points.
    # For education and occupation, the parent with the larger score was chosen per family. 
  
  # Income
    # 1 = 0-1250 Euro
    # 2 = 1250-2000 Euro
    # 3 = 2000-3000 Euro,
    # 4 = 3000-5000 Euro
    # 5 = more than 5000 Euro
  
    qn_data$income_rec[qn_data$income==1 | qn_data$income==2 | qn_data$income==3 | qn_data$income==4] = 1
    qn_data$income_rec[qn_data$income==5 | qn_data$income==6 | qn_data$income==7] = 2
    qn_data$income_rec[qn_data$income==8 | qn_data$income==9 | qn_data$income==10] = 3
    qn_data$income_rec[qn_data$income==11 | qn_data$income==12] = 4
    qn_data$income_rec[qn_data$income==13] = 5
    
  # Education
    # 1 = no degree
    # 2 = secondary modern school [German: "Hauptschule"]
    # 3 = middle school [German: "Realschule"]
    # 4 = advanced technical college entrance qualification [German: "Fachhochschulreife"]
    # 5 = higher education entrance qualification (A-levels) [German: "Abitur"]
  
  # for mum
    qn_data$mum_ed_rec[qn_data$mum_ed==7 | qn_data$mum_ed==8] = 1
    qn_data$mum_ed_rec[qn_data$mum_ed==1 | qn_data$mum_ed==6] = 2
    qn_data$mum_ed_rec[qn_data$mum_ed==2 | qn_data$mum_ed==3] = 3
    qn_data$mum_ed_rec[qn_data$mum_ed==4] = 4
    qn_data$mum_ed_rec[qn_data$mum_ed==5] = 5

  
  # for dad
    qn_data$dad_ed_rec[qn_data$dad_ed==7 | qn_data$dad_ed==8] = 1
    qn_data$dad_ed_rec[qn_data$dad_ed==1 | qn_data$dad_ed==6] = 2
    qn_data$dad_ed_rec[qn_data$dad_ed==2 | qn_data$dad_ed==3] = 3
    qn_data$dad_ed_rec[qn_data$dad_ed==4] = 4
    qn_data$dad_ed_rec[qn_data$dad_ed==5] = 5
  
  # Occupation 
    # 1 = student
    # 2 = skilled worker [German:Gelernter "Facharbeiter"]
    # 3 = foremen/forwomen [German: "Vorarbeiter"]
    # 4 = clerk in the middle grade of the civil service [German: "Beamter mittlerer Dienst"]
    # 5 = senior officials [German: "Beamte h√∂herer Dienst"]
  
  # for mum
    qn_data$occ_mum[qn_data$mum_occup_ISCO==5 | qn_data$mum_occup_ISCO==11 |
                      qn_data$mum_occup_ISCO==12 | qn_data$mum_occup_ISCO==51 | 
                      qn_data$mum_occup_ISCO==52] = 1
    
    qn_data$occ_mum[qn_data$mum_occup_ISCO==13 | qn_data$mum_occup_ISCO==21 |
                      qn_data$mum_occup_ISCO==26 | qn_data$mum_occup_ISCO==31 |
                      qn_data$mum_occup_ISCO==32] = 2
    
    qn_data$occ_mum[qn_data$mum_occup_ISCO==14 | qn_data$mum_occup_ISCO==33 | 
                      qn_data$mum_occup_ISCO==41] = 3
    
    qn_data$occ_mum[qn_data$mum_occup_ISCO==2 | qn_data$mum_occup_ISCO==22 | 
                      qn_data$mum_occup_ISCO==23 | qn_data$mum_occup_ISCO==24 |
                      qn_data$mum_occup_ISCO==34 | qn_data$mum_occup_ISCO==42] = 4
    
    qn_data$occ_mum[qn_data$mum_occup_ISCO==25 | 
                      qn_data$mum_occup_ISCO==35 | qn_data$mum_occup_ISCO==43 |
                      qn_data$mum_occup_ISCO==44] = 5
  
  # for dad
    qn_data$occ_dad[qn_data$dad_occup_ISCO==5 | qn_data$dad_occup_ISCO==11 |
                      qn_data$dad_occup_ISCO==12 | qn_data$dad_occup_ISCO==51 |
                      qn_data$dad_occup_ISCO==52] = 1
    
    qn_data$occ_dad[qn_data$dad_occup_ISCO==13 | qn_data$dad_occup_ISCO==21 | 
                      qn_data$dad_occup_ISCO==26 | qn_data$dad_occup_ISCO==31 | 
                      qn_data$dad_occup_ISCO==32] = 2
    
    qn_data$occ_dad[qn_data$dad_occup_ISCO==14 | qn_data$dad_occup_ISCO==33 | 
                      qn_data$dad_occup_ISCO==41] = 3
    
    qn_data$occ_dad[qn_data$dad_occup_ISCO==2 | qn_data$dad_occup_ISCO==22 | 
                      qn_data$dad_occup_ISCO==23 | qn_data$dad_occup_ISCO==24 |
                      qn_data$dad_occup_ISCO==34 | qn_data$dad_occup_ISCO==42] = 4
    
    qn_data$occ_dad[qn_data$dad_occup_ISCO==25 | qn_data$dad_occup_ISCO==35 |
                      qn_data$dad_occup_ISCO==43 | qn_data$dad_occup_ISCO==44] = 5
  
  # Calculate Winkler index
    # Sum up all points (choose the parent with the larger score). 
  
    for (h in 1:length(qn_data$ID)){
      qn_data$wink_ind[h] = sum(qn_data$income_rec[h],
                            max(qn_data$occ_dad[h],qn_data$occ_mum[h]),
                            max(qn_data$mum_ed_rec[h],qn_data$dad_ed_rec[h]))
    }
    
    
# Based on tutorial: https://cran.r-project.org/web/packages/table1/vignettes/table1-examples.html 
  # Creat for table in RMarkdown: styles.css file in same folder 
      
  # Create labels 
    labels = list(
      variables=list(age = "Child age in years",
                     sex = "Child sex",
                     PPVT_Perc="PPVT (%ile rank)",
                     CMM_Perc="CMM (%ile rank)",
                     SRS = "SRS raw value",
                     SCQ = "SCQ raw value",
                    wink_ind = "Winkler Index")) # this is where you set your headings for the table
    
  # Creates list in which order we want to display columns
    strata <- c(list(Total=qn_data))
    
  # Customize the contents using custom renderers
    my.render.cont = function(x) {
      with(stats.apply.rounding(stats.default(x), digits=3),
           c("", "mean (SD)"=sprintf("%s (%s)", MEAN, SD)))
    }
    
    my.render.cat = function(x) {
      c("", sapply(stats.default(x),
                   function(y) with(y, sprintf("%d (%0.0f %%)", FREQ, PCT))))
    }
    
  # Create table
    table1(strata, labels, render.continuous=my.render.cont, render.categorical=my.render.cat)

```

<br>

### 2.4 EEG recording, processing, and analysis

```{r EEG_attr}

# Combine EEG data and EEG task information ----------------------------------------------------

# List files of EEG/RT within a folder and get number of participants
  files_eeg = list.files(path = "./data/ERPs", pattern="*ind.csv")
  nfiles = length(files_eeg)

# Get RT/Accuracy data for EEG task (please see Script 2 on how to get this data set)
  EEG_behav = readRDS("./data/EEG_behav_data.rds", refhook = NULL)

# Start data concatenation   

for (i in 1:nfiles) {

# Get EEG file per subject
  Subj_Data = read.csv(file=paste("./data/ERPs/",files_eeg[i], sep = ""), header=TRUE, sep=",")

# EEG table transformations -----------------------------------------------

##### Add ID
  Subj_Data$ID = substr(files_eeg [i],1,2)

##### Re-format single conditions into numbers
  Subj_Data$Condition =as.numeric(as.factor(Subj_Data$Condition))

# Reminder: (p=prime, c=comgruent, ic=incongruent)
  # 1 - p_happy; 2 - p_neutral; 3 - p_angry
  # 4 - c_happy; 5 - c_neutral; 6 - c_angry
  # 7 - ic_happy; 8 - ic_neutral; 9 - ic_angry

##### Add group conditions (prime, congruent, incongruent)

# Create grouping variable
  grouping = data.frame(single=c(1:9),group_pcic=c(rep(1,3),rep(2,3),rep(3,3)),
                        group_pt=c(rep(1,3),rep(2,6)),group_en=c(1,2,1,rep(3,6)))

# group_pcic = prime vs congruent vs incongruent, group_pt = prime vs target, group_en = neutral vs emotional prime

# Match grouping variable with subject data
  Subj_Data$Group_pcic = grouping$group_pcic[match(Subj_Data$Condition,grouping$single,nomatch = NA)]
  Subj_Data$Group_pt = grouping$group_pt[match(Subj_Data$Condition,grouping$single,nomatch = NA)]
  Subj_Data$Group_en = grouping$group_en[match(Subj_Data$Condition,grouping$single,nomatch = NA)]

##### Average ROIs
  Subj_Data$mean_ROI_P1 = rowMeans(subset(Subj_Data,select = c(P1_PO3,P1_PO4,P1_O1,P1_O2,P1_Oz)),
                                   na.rm = TRUE)
  Subj_Data$mean_ROI_N170l = rowMeans(subset(Subj_Data,select = c(N170l_TP7,N170l_CP5,N170l_P7)),
                                   na.rm = TRUE)
  Subj_Data$mean_ROI_N170r = rowMeans(subset(Subj_Data,select = c(N170r_TP8,N170r_CP6,N170r_P8)),
                                   na.rm = TRUE)
  Subj_Data$mean_ROI_P3 = rowMeans(subset(Subj_Data,select = c(P3_PO3,P3_PO4,P3_O1,P3_O2,P3_Oz)),
                                   na.rm = TRUE)

# Match EEG table with behavioral information  ------------------------------------------------

# Function to map values together (RT values and ERP trial values): match ()

# Match RTs
  Subj_Data$RTs = EEG_behav$RTs[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]

# Match Responses
  Subj_Data$Response = EEG_behav$Response[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]

# Match Blocks
  Subj_Data$Block = EEG_behav$Block[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]

# Match RT inclusion / exclusion criteria
  Subj_Data$Exclude_smaller_250ms = EEG_behav$Exclude_smaller_250ms[match(Subj_Data$RT_Nr,
                                                                          EEG_behav$Trial_EEG,nomatch = NA)]
  Subj_Data$Exclude_larger_7s = EEG_behav$Exclude_larger_7s[match(Subj_Data$RT_Nr,
                                                                          EEG_behav$Trial_EEG,nomatch = NA)]
  Subj_Data$Exclude_MAD = EEG_behav$Exclude_MAD[match(Subj_Data$RT_Nr,
                                                                          EEG_behav$Trial_EEG,nomatch = NA)]

# Match randomization / stimulus type
  Subj_Data$EEG_Random = EEG_behav$EEG_Random[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]
  Subj_Data$Stim_Type = EEG_behav$Stim_Type[match(Subj_Data$RT_Nr,EEG_behav$Trial_EEG,nomatch = NA)]

# Match age / working memory
  Subj_Data$Age = EEG_behav$Age[match(Subj_Data$ID,EEG_behav$ID,nomatch = NA)]
  Subj_Data$WM = EEG_behav$WM[match(Subj_Data$ID,EEG_behav$ID,nomatch = NA)]

# Combine all subject data ------------------------------------------

  if (i==1) {
    All_Subj = Subj_Data # first round: create all_subj data frame
  } else {
    All_Subj = rbind(All_Subj,Subj_Data) # add to all_subj data frame
  }

  # Clear previous
  remove(Subj_Data)

}

# Remove EEG_Nr & RT_Nr
  All_Subj = subset(All_Subj, select = -c(EEG_Nr,RT_Nr))

# Remove NAs for amplitudes with no clear indication to a block (error during recording of the data)
  All_Subj=All_Subj[complete.cases(All_Subj[ , 28]),]

  sapply(All_Subj,function(x) sum(is.na(x)))


# Trials per emotion condition  ----------------------------------------

# De-select participants 
# 1 = accuracy in EEG task < 50 %
# 5 = ERP components not visible 
  All_Subj = All_Subj[with(All_Subj, !(All_Subj$ID=="01"|All_Subj$ID=="05")), ] 
  
  All_Subj$Response[All_Subj$Response==1] = "correct"
  All_Subj$Response[All_Subj$Response==0] = "incorrect"

# Only choose primes

  All_Subj_p = subset(All_Subj,Group_pt == 1)
  
  All_Subj_p$Condition[All_Subj_p$Condition==1] = "happy"
  All_Subj_p$Condition[All_Subj_p$Condition==2] = "neutral"
  All_Subj_p$Condition[All_Subj_p$Condition==3] = "angry"
  
# Get trial counts   
  emo_trials=data.frame(xtabs(~ID+Condition,All_Subj_p))

# Calculate mean and SD   
  tr_mean_emo = tapply(emo_trials$Freq,emo_trials$Condition,mean)
  tr_sd_emo = tapply(emo_trials$Freq,emo_trials$Condition,sd)

# Calculate one-way ANOVA to test equality of trial numbers
  emo.aov = aov(Freq ~ Condition, data = emo_trials)

# Extract values to present 
  emo.aov.sum = summary(emo.aov)
  emo.aov.sum = data.frame(emo.aov.sum[[1]])
  
```

```{r}
# Trials per repetition condition -----------------------------------------
  
# Only choose targets
  All_Subj$Response[All_Subj$Response==1] = "correct"
  All_Subj$Response[All_Subj$Response==0] = "incorrect"
  
  All_Subj_t = subset(All_Subj,Group_pt == 2) 
  
  All_Subj_t$Group_pcic[All_Subj_t$Group_pcic==2] = "repeated"
  All_Subj_t$Group_pcic[All_Subj_t$Group_pcic==3] = "novel"

# From these trials: only use correct trials 
  All_Subj_t_corr = subset(All_Subj_t,Response == "correct") 
  
# Get trial counts
  rep_trials = data.frame(xtabs(~ID+Group_pcic,All_Subj_t_corr))
  
# Calculate mean and SD   
  tr_mean_rep = tapply(rep_trials$Freq,rep_trials$Group_pcic,mean)
  tr_sd_rep = tapply(rep_trials$Freq,rep_trials$Group_pcic,sd)
  
# Paired-samples t-test
  t_test_res = t.test(rep_trials$Freq[rep_trials$Group_pcic=="novel"], rep_trials$Freq[rep_trials$Group_pcic=="repeated"],
         paired = TRUE, alternative = "two.sided")

```



[...]

The mean number of trials per condition was not significantly different for valence trials (happy: *M* = `r tr_mean_emo[2]`, *SD* = `r tr_sd_emo[2]`, angry: *M* = `r tr_mean_emo[1]`, *SD* = `r tr_mean_emo[1]`, neutral: *M* = `r tr_mean_emo[3]`, *SD* = `r tr_mean_emo[3]`; *F*(`r emo.aov.sum$Df[1]`, `r emo.aov.sum$Df[2]`) = `r emo.aov.sum$F.value[1]`, *p* = `r format.pval(pv = emo.aov.sum$Pr..F.[1], digits = 2, eps = 0.001, nsmall = 3)`)). Trial numbers for repeated trials (*M* = `r tr_mean_rep[2]`, *SD* = `r tr_sd_rep[2]`) were significantly higher (*t*(`r t_test_res$parameter`) = `r t_test_res$statistic`, *p* = `r format.pval(pv = t_test_res$p.value, digits = 2, eps = 0.001, nsmall = 3)`) in comparison to novel trials (*M* = `r tr_mean_rep[1]`, *SD* = `r tr_sd_rep[1]`). 

[...]
